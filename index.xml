<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Leeshy&#39;s Blog | To be humble</title>
        <link>https://leeshy-tech.github.io/</link>
        <description>Welcome to Leeshy&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>saili@bupt.edu.cn (Leeshy)</managingEditor>
            <webMaster>saili@bupt.edu.cn (Leeshy)</webMaster><lastBuildDate>Tue, 14 Jun 2022 14:58:06 &#43;0800</lastBuildDate>
            <atom:link href="https://leeshy-tech.github.io/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>git使用笔记——commit格式</title>
    <link>https://leeshy-tech.github.io/git_commit_format/</link>
    <pubDate>Tue, 14 Jun 2022 14:58:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/git_commit_format/</guid>
    <description><![CDATA[<blockquote>
<p>起因是看到了三位大佬的工程https://github.com/Direktor799/rusted_os/commits/main，非常的赏心悦目，才知道commit也有固定的格式</p>
</blockquote>
<p>Commit Message格式，目前规范使用较多的是 <a href="https://github.com/angular/angular.js/blob/master/DEVELOPERS.md#-git-commit-guidelines" target="_blank" rel="noopener noreffer">Angular 团队的规范</a>, 继而衍生了 <a href="https://www.conventionalcommits.org/en/v1.0.0/" target="_blank" rel="noopener noreffer">Conventional Commits specification</a>. 很多工具也是基于此规范, 它的 message 格式如下:</p>
<p>Commit格式包含三个部分，Header、Body、Footer</p>
<pre tabindex="0"><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;
&lt;BLANK LINE&gt;
&lt;body&gt;
&lt;BLANK LINE&gt;
&lt;footer&gt;
</code></pre><ul>
<li>首行header：必填，描述修改类型和内容
<ul>
<li>scope：commit影响的范围</li>
<li>subject：commit的概述</li>
</ul>
</li>
<li>body：commit具体修改的内容</li>
<li>footer：备注，通常是 BREAKING CHANGE 或修复的 bug 的链接.</li>
</ul>
<h3 id="header">Header</h3>
<p>Header只有一行，包括三个字段<code>type</code>（必填）<code>scope</code>（可选）<code>subject</code>（必填）</p>
<h4 id="type">type</h4>
<p>说明commit的类别</p>
<ul>
<li>feat：新增功能</li>
<li>fix：bug 修复</li>
<li>docs：文档更新</li>
<li>style：不影响程序逻辑的代码修改(修改空白字符，格式缩进，补全缺失的分号等，没有改变代码逻辑)</li>
<li>refactor：重构代码(既没有新增功能，也没有修复 bug)</li>
<li>perf：性能, 体验优化</li>
<li>test：新增测试用例或是更新现有测试</li>
<li>build：主要目的是修改项目构建系统(例如 glup，webpack，rollup 的配置等)的提交</li>
<li>ci：主要目的是修改项目继续集成流程(例如 Travis，Jenkins，GitLab CI，Circle等)的提交</li>
<li>chore：不属于以上类型的其他类，比如构建流程, 依赖管理</li>
<li>revert：回滚某个更早之前的提交</li>
</ul>
<h4 id="scope">scope</h4>
<p>说明commit影响的范围，比如文件或者逻辑层。</p>
<h4 id="subject">subject</h4>
<p>commit简述</p>
<ul>
<li>以动词开头，使用第一人称现在时，比如<code>change</code>，而不是<code>changed</code>或<code>changes</code></li>
<li>第一个字母小写</li>
<li>结尾不加句号（<code>.</code>）</li>
</ul>
<h3 id="body">Body</h3>
<p>commit详细描述</p>
<h3 id="footer">Footer</h3>
<p>只用于两种情况</p>
<ol>
<li>不兼容变动</li>
<li>关闭Issue</li>
</ol>
]]></description>
</item>
<item>
    <title>论文笔记——Oracle-MNIST：a Realistic Image Dataset for Benchmarking Machine Learning Algorithms</title>
    <link>https://leeshy-tech.github.io/oracle-mnist/</link>
    <pubDate>Sun, 12 Jun 2022 14:13:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/oracle-mnist/</guid>
    <description><![CDATA[<h2 id="摘要">摘要</h2>
<p>​	我们引入了Oracle-MNIST数据集，包括10个类别的30222个古代字符的28×28灰度图像，用于基准模式分类，特别是图像噪声和失真方面的挑战。训练集共有27222张图像，测试集每个类有300张图像。Oracle-MNIST与原始MNIST数据集共享相同的数据格式，允许与所有现有的分类器和系统直接兼容，但它构成了比MNIST更具挑战性的分类任务。由于三千年的埋藏和老化，古文字的形象受到了极其严重和独特的噪音影响，以及古文字的书写风格的巨大变化，这些都使其具有机器学习研究的现实感。该数据集可以在https://github.com/wm-bupt/oracle-mnist上免费获得。</p>
<h2 id="1-引言">1 引言</h2>
<p>​	在过去的几年里，由于专门的数据集作为实验测试平台和当前进展的公共基准的发布，机器学习(ML)取得了快速的进展，从而集中了研究社区的努力。计算机视觉中最广为人知的数据集是MNIST数据集，该数据集于1998年由LeCun等人(1998)首次引入。MNIST是一个10类数字分类数据集，由60,000张用于训练的灰度图像和10,000张用于测试的灰度图像组成。整个数据集相对较小，可以自由访问和使用，并以完全直接的方式进行编码和存储，这几乎肯定有助于它的广泛使用。</p>
<p>​	然而，随着改进学习算法的发现，MNIST的性能已经饱和。例如，卷积神经网络(CNNs) (Krizhevsky等人，2012;He et al.， 2016)可以轻松达到99%以上的准确率。这部分归因于基准测试没有捕获许多真实场景的需求。为了避免饱和性能并为改进的ML算法提供挑战，构建了一些改进的MNIST数据集，例如EMNIST (Cohen等人，2017)和fashionn -MNIST (Xiao等人，2017)。EMNIST通过引入大写和小写字符扩展了类的数量，但额外的类需要改变MNIST使用的深度神经网络的框架。fashion - mnist包含10级时尚产品的7万张灰度图像。这些产品图片来源于Zalando的网站e1，由专业摄影师拍摄，清晰规范。然而，它未能在现实世界中尽可能广泛地捕捉各种变化。</p>
<p>​	本文的目的是提供一个真实且具有挑战性的数据集Oracle-MNIST，以方便ML算法对真实的古代字符图像进行简单快速的评估。oracle - mnist包含属于10个类别的oracle字符的30222个图像。</p>
<p></p>
<ol>
<li>
<p>真实世界的挑战。</p>
<p>与手写数字不同，甲骨文字符是从真实的甲骨文表面扫描而来。因此，Oracle-MNIST由于数千年的埋藏和老化而产生了极其严重和独特的噪音，并且在每个类别中都包含着各种各样的写作风格，这都使得ML研究更加现实和困难。</p>
</li>
<li>
<p>易用性。</p>
<p>与原来的MNIST相同，图像在Oracle-MNIST有28×28灰度像素。它可以立即兼容任何能够与MNIST数据集工作的ML包，因为它共享相同的数据格式。事实上，使用这个数据集需要做的唯一更改就是更改获取MNIST数据集的URL。</p>
</li>
</ol>
<h2 id="2-oracle-mnist-数据集">2 Oracle-MNIST 数据集</h2>
<h3 id="21甲骨文字符发现">2.1甲骨文字符发现</h3>
<p>​	古代史依赖于对古文字的研究。甲骨文是中国最古老的象形文字(Flad et al.， 2008;Keightley, 1997)，近三千年的历史，为现代文明做出了巨大的贡献，使中华文化得以代代相传，成为唯一延续至今的文明。如图1所示，甲骨文被镌刻在龟甲和兽骨上，记录了商朝(公元前1600-1046年)的生活和历史，包括占卜、征战、狩猎、医疗和生育等。1899年，清朝(1644-1911)，一位名叫王希荣的商人首次发现了它们。20世纪初，中国的研究人员在商朝都城河南安阳的小屯村发掘了大量的甲骨文。此后，甲骨文文字的研究备受关注。它对于中国的词源学和书法，以及学习中国古代乃至世界的文化和历史都具有重要的意义。</p>
<p></p>
<p></p>
<p></p>
<p>​	甲骨文字符大多采用扫描图像存储，扫描图像是将一张纸盖在主体上，然后用卷墨拓印，再现甲骨文表面，如图2(a)所示。识别这些甲骨文字符对专家和机器来说都很困难。到目前为止，已经发现了近4500个不同的甲骨文字符，但只有大约2200个字符被成功破译。原因如下。(1)磨损和噪声。几个世纪以来，许多甲骨铭文遭到破坏，它们的文字现在已经残缺不全。铭文的老化过程也使其不易辨认，因此扫描的文字破损，并含有严重的噪音。(2)大方差。不同的写作风格导致了类内的高度差异。如图2(b)所示，属于同一类别的字符在笔画甚至拓扑结构上都存在较大差异。不同类别的一些字符彼此相似，这给识别带来了很大的困难。例如，图2(c)和图2(d)所示的“木”和“牛”两个类别的字符仅在一些小细节上有所不同。</p>
<h3 id="22-数据集的细节">2.2 数据集的细节</h3>
<p>​	Oracle-MNIST是基于<em>殷奇文苑网站</em>的集合。这些甲骨文字是从真实的甲骨文表面扫描而来的，因此会出现破碎和噪音严重的现象。每个扫描图像的中心都有一个字符。大多数原始图像都有灰色或黑色背景，分辨率也各不相同。</p>
<p>​	我们选择了10个类的30222个常用字符构建Oracle-MNIST。然后将原始图像送入下面的转换管道，如图3所示。我们还试图通过一些图像增强技术，如灰度拉伸和直方图均衡化来处理图像。虽然成功地提高了图像的视觉质量，但识别性能略有下降。因此，Oracle-MNIST并没有采用图像增强技术。我们还提供原始图像，并将数据处理工作留给算法开发人员。</p>
<ol>
<li>将图像转换为8位灰度像素。</li>
<li>如果前景比背景暗，则取消图像的强度。</li>
<li>使用双三次插值算法将图像的最长边缘调整为28。</li>
<li>将最短的边延长到28，并将图像放到画布的中心。</li>
</ol>
<p>​	我们利用字符的含义作为它们的类标签。这些标签是由考古学或古生物学专家手工标注的。表2给出了Oracle-MNIST中所有类标签的总结，并给出了每个类的示例。</p>
<p>​	最后，我们将数据集分为训练集和测试集，并确保它们是不相交的。训练集由随机选取的27222张图像组成，测试集每类包含300张图像。图像和标签以与MNIST数据集相同的文件格式存储，MNIST数据集是为存储向量和多维矩阵而设计的。表1列出了结果文件。</p>
<p></p>
<h2 id="3-实验">3 实验</h2>
<p>​	我们在Oracle-MNIST上评估了一些不同参数的算法，结果如表3所示。对于每种算法，通过三次重复实验报告了平均分类精度。MNIST和Fashion-MNIST数据集上的基准也包括在并排比较中。</p>
<p>​	从结果中，我们有以下观察结果。首先，经典(浅层)ML算法在MNIST数据集上可以轻松实现97%，这证明了MNIST算法太容易评估。我们的Oracle-MNIST数据集提供了10类古代字符的图像，并进一步捕捉了现实世界中尽可能广泛的变化，这比MNIST数字数据和Fashion-MNIST数据提出了更具有挑战性的分类任务。我们可以看到，所有经典的(浅)ML算法在MNIST上表现最好，其次是fashionmnist，在oracle MNIST上表现最差。例如，随机森林分类器的准确率分别为97.1%、87.1%和64.9%。这是因为上文2.1节所述的类内方差和类间相似度较高，会给分类带来很大的困难。此外，由于模糊、噪声和遮挡等原因，扫描到的甲骨文图像会严重退化，甚至完全失去识别字形信息。</p>
<p>​	其次，CNN优于Oracle-MNIST上所有的经典(浅)ML算法。得益于局部接收场和空间或时间子采样，CNN可以强制提取局部特征，降低输出对位移和失真的敏感性(LeCun et al.， 1995)。因此，现实世界的挑战，如不同的写作风格，噪音和闭塞，可以在一定程度上解决。然而，Oracle-MNIST上的性能还没有饱和。本文使用的CNN在Oracle-MNIST上的错误率为6.2%，还有改进的空间。尽管CNN具有强大的表示能力，但是识别这些古文字的问题还有待完全解决。</p>
<p></p>
<p></p>
<p></p>
<p></p>
<h2 id="4-结论">4 结论</h2>
<p>​	在本文中，我们提出了一个现实的和具有挑战性的基准数据集，即Oracle-MNIST。它包含10类30222个古文字的28×28灰度图像，用于对计算机视觉中的图像噪声和失真的鲁棒性进行基准测试。Oracle-MNIST被转换成一种与构建来处理MNIST数据集的分类器直接兼容的格式。由于数千年的埋藏和老化，这些古老的文字噪音大，书写风格各异，给识别带来了很大的困难。基准测试结果表明，古文字分类任务确实更具挑战性。</p>
]]></description>
</item>
<item>
    <title>论文笔记——AMM: Attentive Multi-field Matching for News Recommendation Matching</title>
    <link>https://leeshy-tech.github.io/ammattentive_multi-field_matching/</link>
    <pubDate>Tue, 24 May 2022 17:41:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/ammattentive_multi-field_matching/</guid>
    <description><![CDATA[<h1 id="amm-attentive-multi-field-matching-for-news-recommendation">AMM: Attentive Multi-field Matching for News Recommendation</h1>
<h2 id="论文概况">论文概况</h2>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3404835.3463232" target="_blank" rel="noopener noreffer">https://dl.acm.org/doi/abs/10.1145/3404835.3463232</a></p>
<p>SIGIR &lsquo;21: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</p>
<p>July 2021 Pages 1588–1592</p>
<p><a href="https://doi.org/10.1145/3404835.3463232" target="_blank" rel="noopener noreffer">https://doi.org/10.1145/3404835.3463232</a></p>
<p>自翻：<a href="https://github.com/leeshy-tech/PaperTranslate/blob/main/AMMAttentive_Multi-field_Matching.md" target="_blank" rel="noopener noreffer">https://github.com/leeshy-tech/PaperTranslate/blob/main/AMMAttentive_Multi-field_Matching.md</a></p>
<h2 id="引言">引言</h2>
<p>​		用户兴趣与候选新闻的准确匹配是准确的个性化新闻推荐的前提。现有的方法主要是通过顺序或注意力模型聚合用户之前浏览过的新闻来学习用户的兴趣向量，然后将其与候选新闻向量进行匹配，取得了相当大的进展。例如，NPA [12] 根据候选新闻和之前点击的新闻之间的相似性来学习用户表示。 LSTUR [1] 使用 GRU 网络从点击的新闻中模拟短期和长期的用户兴趣。 NAML [11] 和 NRMS [13] 应用注意力网络从点击的新闻中学习用户表示。 FIM [9] 为每个新闻提取多级表示，并通过卷积执行细粒度匹配。然而，这些方法中的大多数将每个用户和新闻表示为单个向量，这可能会丢失文本匹配信号（例如，词级关系）。因此，我们的方法不是简单地将用户浏览的新闻建模为一个整体，而是关注每个浏览的候选新闻对之间的关系，以捕获细粒度的语义匹配表示。此外，这种对设计是在线服务友好的，匹配的表示可以离线存储，以避免重复计算。在这里，我们首先使用 BERT 来学习每个浏览候选新闻对在不同语义级别的匹配表示，然后将它们聚合到最终的用户新闻匹配信号。</p>
<p>​	此外，上述方法基于单视图新闻信息[1,9,13]或多视图信息[11]学习新闻之间的语义相关性，它们仅利用字段内语义相关性（例如，标题-标题，正文-正文）。 但有时，跨领域信息（例如标题-摘要、标题-正文）可能有利于新闻匹配。 比如新闻𝑎的标题信息丰富，而新闻𝑏的标题很吸引人，新闻𝑎的标题和新闻𝑏的正文匹配可能更好。 因此，与每条新闻相关的多个字段可能包含互补信息，这些信息促使我们学习多字段（字段内和跨字段）匹配表示。</p>
<p>​	在本文中，我们提出了一种注意力多字段匹配（AMM）框架，该框架捕获每个浏览候选新闻对的多字段语义匹配表示，然后将这些表示聚合为最终的用户新闻匹配信号，用于新闻推荐。 这项工作的主要贡献总结如下：</p>
<ul>
<li>我们提出了一种新的方法，专注于分离的浏览候选新闻对的匹配，以捕获文本语义匹配信号，这对在线服务很友好。</li>
<li>我们设计了 AMM 框架，以在领域内和跨领域的方式中提取多领域匹配表示，以深入探索用户的兴趣。</li>
<li>我们对两个公共基准数据集进行了实验，以证明我们方法的有效性。</li>
</ul>
<h2 id="我们的方法">我们的方法</h2>
<p>图 1 显示了 AMM 的整体架构。 首先，我们为每个浏览的候选新闻构建多字段对输入。 然后，匹配编码器用于提取每对输入的匹配表示。 最后，我们将所有对的匹配表示聚合到用户新闻信号以估计点击概率。</p>
<p></p>
<h3 id="21-多头部匹配">2.1 多头部匹配</h3>
<p>​	不同的新闻字段通常可以相互补充。 为了更好地编码浏览-候选匹配，我们利用字段内和跨字段匹配作为多字段信息来增强匹配表示。</p>
<p>​	给定用户浏览的新闻$\left[N_{1}, N_{2}, \ldots, N_{i}\right]$和候选新闻$N_x$，对于每个浏览-候选对$\left(N_{i}, N_{c}\right)$，我们建立多头部对输入$\left[N_{i}^{m}, N_{c}^{n}\right]$，其中$m \in{t, a, b},n \in{t, a, b}$，t、a、b分别是新闻的标题、摘要、主体。我们将新闻标题$N^t$表示为词向量$\left[w_{1}^{t}, w_{2}^{t}, \ldots, w_{\left|N^{t}\right|}^{t}\right]$，新闻摘要$N^a$表示为$\left[w_{1}^{a}, w_{2}^{a}, \ldots, w_{|N a|}^{a}\right]$，新闻主体$N^b$表示为$\left[w_{1}^{b}, w_{2}^{b}, \ldots, w_{\left|N^{\prime}\right|}^{b}\right]$，其中$\left|N^{t}\right|\left|N^{a}\right|$和$\left|N^{b}\right|$分别表示标题、摘要、主体的长度。</p>
<p>​	在这项研究中，如图 1 所示，不仅像$\left[N_{i}^{t}, N_{c}^{t}\right]$（标题和标题）这样的字段内对输入，而且像$\left[N_{i}^{t}, N_{c}^{b}\right]$（标题和正文）这样的跨字段对输入都被获得 ，这些输入对中的每一个都被馈送到匹配编码器以获得其匹配表示。 我们最终将这些表示串接为浏览候选新闻对的多字段匹配表示。</p>
<h3 id="22-匹配编码器">2.2 匹配编码器</h3>
<p>该模块用于学习每个浏览过的新闻和候选新闻之间的语义匹配。 我们将来自多字段匹配的浏览-候选多字段对作为输入，然后将其输入到来自 Transformers (BERT) [4] 的双向编码器表示中，以进行匹配表示学习。</p>
<ul>
<li>
<p>多头部自注意层</p>
<p>该子层旨在捕获句子的上下文感知语义匹配。 使用多头，来自不同位置的不同语义子空间的信息是可联合学习的，这对于捕获不同标记之间的匹配信号非常有帮助。</p>
</li>
<li>
<p>位置智慧型前馈网络</p>
<p>这个子层的目的是赋予模型非线性和不同维度之间的相互作用，这是一个完全连接的前馈网络(FFN)，它由两个线性变换组成，中间有一个ReLU激活。</p>
</li>
</ul>
<p>另外，对每个子层进行残差连接和层归一化处理。最后，我们可以通过该匹配编码器得到每个浏览-候选新闻的多字段对的匹配表示。</p>
<h3 id="23-匹配聚合器">2.3 匹配聚合器</h3>
<p>​	匹配聚合器用于聚合每个浏览新闻和候选新闻的匹配表示，以获得最终的用户新闻匹配信号。我们使用以下三种类型的聚合器获得最终的用户新闻匹配表示$\tilde{M}$：</p>
<ul>
<li>
<p>最大/平均聚合器：对的匹配嵌入直接取最大或平均作为用户-新闻匹配嵌入。
$$
\tilde{M}=\text { Aggregate }(M)=\max / \operatorname{mean}(M)\tag 5
$$</p>
</li>
<li>
<p>注意力聚合器：使用门限注意网络 [2] 来学习 𝑀 的组合权重，它应用具有$W_h$和$b_h$的全连接神经网络，使用 tanh 作为第一层激活函数，然后使用$W_o$和$b_o$构造第二个全连接神经网络来学习在等式（6）中定义的组合权重 𝑟 ，最后在等式（7）中计算词向量的线性组合。
$$
\tilde{M}=\text { Aggregate }(M)=\mathbf{r}^{\top} M\tag 6
$$</p>
<p>$$
r=\operatorname{softmax}\left(\tanh \left(\tilde{E} W_{h}+b_{h}\right) W_{o}+b_{o}\right)\tag 7
$$</p>
</li>
</ul>
<h3 id="24-点击预测">2.4 点击预测</h3>
<p>最后，我们介绍点击预测模块。 将<strong>用户-新闻匹配表示</strong>表示为$\tilde{M}$，点击概率 𝑦 通过应用全连接层计算：
$$
y=\operatorname{softmax}\left(\tilde{M} W^{o}+b^{o}\right)\tag 8
$$
其中$W^{o} \in \mathbb{R}^{d^{\prime} \times 1}$和$b^{o} \in \mathbb{R}^{1}$是可学习参数。</p>
<h2 id="3-实验">3 实验</h2>
<h3 id="31-实验设置">3.1 实验设置</h3>
<h4 id="数据集">数据集</h4>
<ul>
<li>MIND</li>
<li>Adressa</li>
</ul>
<h4 id="评价指标">评价指标</h4>
<p>​	我们使用 AUC、MRR、nDCG@𝐾，其中𝐾 = 5, 10 用于 MIND，𝐾 = 1, 3 用于 Adressa，作为我们的评估指标。 性能是所有展示日志中这些指标的平均值。</p>
<h3 id="32-性能评估">3.2 性能评估</h3>
<p>​	我们通过将 AMM 与几种基准方法进行比较来评估 AMM 的性能，</p>
<ul>
<li>LibFM [8]，分解机（FM）；</li>
<li>DeepFM[6]：一种结合了FM和神经网络的深度分解机；</li>
<li>DKN[10]，一种基于知识感知CNN的深度新闻推荐方法；</li>
<li>NPA[12]，引入注意力机制来选择重要的词和新闻；</li>
<li>NAML [11]，一种具有注意力多视图学习的神经新闻推荐方法；</li>
<li>LSTUR [1]，它使用 GRU 从点击历史中对短期和长期兴趣进行建模；</li>
<li>NRMS [13]，它使用多头自注意力来学习用户和新闻表示；</li>
<li>FIM[9]，一种用于神经新闻推荐的细粒度兴趣匹配方法；</li>
<li>AMM，我们的方法。</li>
</ul>
<p></p>
<ul>
<li>使用深度神经网络提取新闻语义表示的方法（3-8）比基于特征的方法（1-2）表现更好。这种性能改进应归功于更好的新闻表示方法。</li>
<li>在方法（3-8）中，NAML 在 MIND 中表现最好，NRMS 在 Adressa 中表现最好，这是因为 NAML 使用了不同种类的新闻信息，而 NRMS 应用了多头自注意力来进一步捕捉单词和点击新闻互动。 FIM 在所有基线中的 Adressa 中表现最好，因为它可以捕获更细粒度的兴趣匹配信号。</li>
<li>我们提出的 AMM 通过考虑分离的浏览候选新闻对和跨字段匹配来捕获多字段的更好的文本语义匹配，在所有指标方面在两个数据集上实现了最佳性能。</li>
</ul>
<h3 id="33-消融实验">3.3 消融实验</h3>
<p></p>
<ul>
<li>比较了AMM与三个单一字段(标题、摘要、正文)在MIND上的性能。
<ul>
<li>带有标题和正文的AMM的表现优于带有摘要的AMM，这表明标题和正文比摘要更有利于新闻表征。</li>
<li>此外，单个标题或正文的AMM的性能优于最佳基准，表明了分离策略引入文本语义匹配的必要性。</li>
</ul>
</li>
<li>通过实验验证了多领域匹配的有效性。
<ul>
<li>AMM多字段比AMM内字段性能更好，这可能是因为通过跨字段匹配可以融合更多的互补信息，字段内和多字段信息的集成可以提高用户新闻匹配，捕捉细粒度用户的兴趣。</li>
</ul>
</li>
<li>探讨了不同匹配聚合器的有效性。
<ul>
<li>我们可以看到带有注意力聚合器的 AMM 的性能略好于带有最大+平均池化的 AMM。 而且，最大+平均池化的表现也比 最佳基准方法好很多，验证了多字段语义匹配的有效性，这些简单的操作让在线服务更有可能。</li>
</ul>
</li>
</ul>
<h2 id="结论">结论</h2>
<p>​	在本文中，我们提出了一种新颖的注意力多领域匹配（AMM）新闻推荐框架。 我们建议以新闻分离的方式学习用户-新闻匹配表示，捕获每对浏览候选新闻的匹配表示，然后将这些表示聚合为最终匹配信号，从而获得细粒度的语义匹配信息以及它是在线服务友好的。 此外，我们的方法同时考虑了字段内和跨字段作为多字段匹配，利用了字段间的互补信息，提高了新闻对的匹配表示。 两个公共基准数据集的实验结果证明了 AMM 的最新性能。</p>
]]></description>
</item>
<item>
    <title>论文笔记——Personalized News Recommendation with Knowledge-aware Interactive Matching</title>
    <link>https://leeshy-tech.github.io/personalized_news_recommendation/</link>
    <pubDate>Mon, 23 May 2022 15:03:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/personalized_news_recommendation/</guid>
    <description><![CDATA[<h1 id="personalized-news-recommendation-with-knowledge-aware-interactive-matching">Personalized News Recommendation with Knowledge-aware Interactive Matching</h1>
<p>基于知识感知交互匹配的个性化新闻推荐</p>
<h2 id="论文概况">论文概况</h2>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3404835.3462861" target="_blank" rel="noopener noreffer">https://dl.acm.org/doi/abs/10.1145/3404835.3462861</a></p>
<p>SIGIR &lsquo;21: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</p>
<p>July 2021 Pages 61–70</p>
<p><a href="https://doi.org/10.1145/3404835.3462861" target="_blank" rel="noopener noreffer">https://doi.org/10.1145/3404835.3462861</a></p>
<p>自翻：<a href="https://github.com/leeshy-tech/PaperTranslate/blob/main/Personalized_news_recommendation_with_%20Knowledge-aware_Interactive_Matching.md" target="_blank" rel="noopener noreffer">https://github.com/leeshy-tech/PaperTranslate/blob/main/Personalized_news_recommendation.md</a></p>
<h2 id="摘要">摘要</h2>
<p>​	在本文中，我们提出了一种用于新闻推荐的知识感知交互式匹配方法。我们的方法以交互方式对候选新闻和用户兴趣进行建模，以促进它们的准确匹配。我们设计了一个知识感知新闻协同编码器，在知识图谱的帮助下捕获它们在语义和实体中的相关性，交互式地学习点击新闻和候选新闻的表示。我们还设计了一个用户新闻协同编码器来学习候选新闻感知用户兴趣表示和用户感知候选新闻表示，以实现更好的兴趣匹配。在两个真实世界数据集上的实验验证了，我们的方法可以有效地提高新闻推荐的性能。</p>
<h2 id="1-引言">1 引言</h2>
<p>​	现有方法通常根据其文本信息对候选新闻进行建模，并以独立的方式从用户的点击历史中推断出用户兴趣[21, 37]。 候选新闻文章可能包含多个方面和实体 [18、33]，并且用户可能有多个兴趣 [32]。 因此，候选新闻和用户兴趣的独立建模可能不如兴趣匹配[31]。</p>
<p>​	在本文中，我们探索更好地模拟候选新闻和用户兴趣之间的相关性，以实现准确的兴趣匹配。 我们的论文受到以下观察的启发。</p>
<p></p>
<ol>
<li>
<p>候选新闻可能涵盖不同的方面和实体，并且用户可能有多种兴趣。</p>
<p>例如，图中 候选新闻2 与篮球明星和政治家有关，含有多个实体（库里和特朗普）。示例用户对车、音乐、体育等领域感兴趣，第二个候选新闻只能匹配特定的用户兴趣即“体育”，但是用户可能只对实体“库里”感兴趣。所以如果独立建模，用候选新闻匹配用户兴趣的效果是较差的。</p>
</li>
<li>
<p>候选新闻和点击新闻的语义匹配有助于更准确地进行兴趣匹配。</p>
<p>例如，第二条点击新闻也与第一条候选新闻有语义相关性，因为它们提到了相同的事件。基于这些语义相关性，我们可以推断用户可能对第一个候选新闻感兴趣。</p>
</li>
<li>
<p>借助知识图谱，点击新闻和候选新闻中实体之间的知识匹配也有助于了解用户对候选新闻的兴趣。</p>
<p>例如，第 4 条点击新闻中的实体“史蒂夫·科尔”与第 2 条候选新闻中的实体“斯蒂芬·库里”具有内在关联，因为前者和后者分别是“NBA”勇士队的球员和教练。根据知识匹配，我们可以推断出用户可能对第二个候选新闻感兴趣。因此，在语义和知识层面利用点击新闻和候选新闻之间的相关性有利于兴趣匹配。</p>
</li>
</ol>
<p>​	在本文中，我们提出了一种用于个性化新闻推荐的知识感知交互式匹配框架（命名为KIM）。我们的方法可以交互地对候选新闻和用户兴趣进行建模，以学习候选新闻感知的用户兴趣表示和用户感知的候选新闻表示，从而更准确地匹配用户兴趣和候选新闻。在该框架中，我们提出了一种知识协同编码器，借助知识图谱从点击新闻中的实体与候选新闻中的实体之间的相关性来建模用户对候选新闻的兴趣。</p>
<p>​	更具体地说，我们</p>
<ol>
<li>
<p>首先提出了一个<strong>图协同注意网络（ graph co-attention network）</strong>：</p>
<p>它通过选择和聚合对兴趣匹配有用的邻居，从知识图谱中学习实体的表示。</p>
</li>
<li>
<p>进一步提出了使用<strong>实体协同注意力网络（ entity co-attention network）</strong>：</p>
<p>它通过捕获实体之间的相关性来交互式地学习点击新闻和候选新闻的基于知识的表示。</p>
</li>
<li>
<p>提出了一种<strong>语义协同编码器（ semantic coencoder）</strong>：</p>
<p>通过对文本之间的语义相关性进行建模，交互式地学习用户点击新闻和候选新闻的基于语义的表示。新闻的统一表示被表述为基于知识和语义的表示的聚合。</p>
</li>
<li>
<p>进一步提出了一种<strong>用户新闻联合编码器（ user-news co-encoder）</strong>：</p>
<p>用于从点击新闻和候选新闻的表示中构建候选<em>新闻感知的用户兴趣表示</em>和<em>用户感知的候选新闻表示</em>，以更好地模拟用户对候选新闻的兴趣。最后，根据候选新闻的表示与用户兴趣之间的相关性对候选新闻进行排名。</p>
</li>
</ol>
<p>我们对两个真实的数据集进行了广泛的实验，并表明我们的方法可以有效地提高新闻推荐的性能并优于其他基准方法。</p>
<h2 id="2-相关的工作">2 相关的工作</h2>
<p>​	现有方法通常通过内容对候选新闻进行建模，并根据点击新闻独立建模用户兴趣，然后根据候选新闻和用户兴趣的相关性进行匹配。 只有一部分候选新方面和用户兴趣对匹配用户兴趣和候选新闻有用。然而，这些方法独立地对候选新闻和用户兴趣进行建模，这对于进一步的兴趣匹配可能较差。与这些方法不同的是，在 KIM 方法中，我们提出了一个知识感知的交互式匹配框架，在考虑相关性的情况下对候选新闻和用户兴趣进行交互建模，可以更好地将用户兴趣与候选新闻进行匹配。</p>
<p>​	一些方法以候选感知的方式模拟用户兴趣。事实上，候选新闻可能包含多个方面和实体，其中只有一部分可能与用户兴趣相匹配。然而，这些方法在没有考虑目标用户的情况下对候选新闻进行建模，这对于进一步将用户兴趣与候选新闻进行匹配可能较差。与这些方法不同，我们的 KIM 方法在考虑目标用户的情况下对候选新闻进行建模。此外，这些方法在没有考虑相关性的情况下对点击新闻和候选新闻进行建模，这对于进一步衡量候选新闻和从点击新闻推断出的用户兴趣之间的相关性也可能不是最优的。与这些方法不同，KIM 可以交互地学习点击新闻和候选新闻的表示，以实现更好的兴趣匹配。</p>
<h2 id="3-方法论">3 方法论</h2>
<h3 id="问题表述">问题表述</h3>
<p>​	给定一个用户𝑢和一个候选新闻$n^c$，我们需要计算相关性分数𝑧来衡量用户𝑢对候选新闻内容$n^c$的兴趣。 然后根据相关性得分对不同的候选新闻进行排名并推荐给用户𝑢。 用户𝑢与他/她点击的新闻集相关联。 每个新闻 𝑛 都与其文本 𝑇 和文本中的实体 𝐸 相关联。 此外，还有一个知识图 G 用于提供实体之间的相关性。 它包含实体和实体之间的关系。 G 中的每个实体 𝑒 与其嵌入相关联，e 基于知识图进行预训练。</p>
<p></p>
<h3 id="kim-knowledge-aware-interactive-matching的框架">KIM（ Knowledge-aware Interactive Matching）的框架</h3>
<p>​	KIM 包含两个主要模块。：</p>
<ol>
<li>
<p>第一个是知识感知新闻协同编码器（knowledge-aware news co-encoder），它通过捕获语义和知识层面的相关性，交互式地学习用户<strong>点击新闻</strong>和<strong>候选新闻</strong>的<strong>知识感知表示</strong>（ knowledge-aware representations）。</p>
</li>
<li>
<p>第二个是用户新闻协同编码器（user-news co-encoder），它从上个模块生成的用户<strong>点击新闻的表征</strong>和<strong>候选新闻表征</strong>中交互学习候选新闻感知的用户兴趣表征（ candidate news-aware user interest representation）u和用户感知的候选新闻表征（ user-aware candidate news representation）。</p>
</li>
</ol>
<h3 id="知识感知新闻协同编码器knowledge-aware-news-co-encoder">知识感知新闻协同编码器（knowledge-aware news co-encoder）</h3>
<p>​	它从文本和文本中的实体中交互式地学习用户点击的新闻$n_u$和候选新闻$n_c$的表示，它包含三个子模块。</p>
<p></p>
<ol>
<li>
<p>第一个是知识协同编码器（Knowledge co-encoder）</p>
<p>对于点击新闻$n_u$和候选新闻$n_c$，它基于知识图谱从<strong>实体</strong>之间的相关性中交互式地学习基于知识的表示${k}^{u}$$和 $${k}^{c}$。</p>
<p>它包含三个组件：</p>
<ul>
<li>图注意网络（ graph attention network）</li>
<li>图协同注意网络（ graph co-attention network）</li>
<li>实体协同注意网络（ entity co-attention network）</li>
</ul>
<p></p>
</li>
<li>
<p>第二个是语义协同编码器（semantic co-encoder）</p>
<p>对于点击新闻$n_u$和候选新闻$n_c$，它交互式地学习基于语义的表示${t}^{u}$和${t}^{c}$，以根据<strong>文本</strong>之间的语义相关性来模拟用户对候选新闻的兴趣。</p>
<p></p>
</li>
<li>
<p>最后，对于点击新闻$n_u$或候选新闻$n_c$，我们投影其基于<strong>知识</strong>和<strong>语义</strong>的表示来学习统一的新闻表示${n}^{u}$或${n}^{c}$。</p>
</li>
</ol>
<h3 id="用户-新闻-协同编码器">用户-新闻 协同编码器</h3>
<p>​	它从用户点击的新闻和候选新闻的表示中学习候选新闻感知的用户兴趣表示和用户感知的候选新闻表示。</p>
<p>​	通常，用户的兴趣是多样的，只有一部分可以与候选新闻匹配[20]。因此，学习候选<strong>新闻感知的</strong>用户兴趣表示可以更好地建模用户兴趣以匹配候选新闻。</p>
<p>​	类似地，候选新闻可能涵盖多个方面，用户可能只对其中的一部分感兴趣 [33, 34]。因此，学习<strong>用户感知的</strong>候选新闻表示也有利于兴趣匹配。</p>
<p>​	因此，我们应用新闻协同注意网络来学习候选新闻感知用户表示和用户感知候选新闻表示。</p>
<h2 id="实验">实验</h2>
<h3 id="数据集">数据集</h3>
<ul>
<li>MIND2</li>
<li>Feeds</li>
</ul>
<p>此外，我们在实验中使用了 WikiData 作为知识图谱。</p>
<h3 id="性能评估">性能评估</h3>
<p>​	我们将 KIM 与几种最先进的个性化新闻推荐方法进行比较，如下所示：</p>
<ul>
<li>EBNR [21]：通过 GRU 网络从用户的点击历史中表示用户兴趣。</li>
<li>DKN [32]：将多通道 CNN 网络 [15] 应用于新闻标题中对齐的单词和实体的嵌入，以学习新闻表示。</li>
<li>DAN [47]：通过 CNN 网络从新闻标题的单词和实体中学习新闻表示，并通过细心的 LSTM 网络 [8] 学习用户兴趣表示。</li>
<li>NAML [33]：通过多个注意力集中的 CNN 网络从新闻标题、正文、类别和子类别中学习新闻表示。</li>
<li>NPA [34]：使用具有个性化注意查询的注意网络来学习新闻和用户表示。</li>
<li>LSTUR [1]：通过 GRU 网络从用户最近点击的新闻中建模短期用户兴趣，并通过用户 ID 嵌入建模长期用户兴趣。</li>
<li>NRMS [37]：通过多头自注意力网络对新闻内容和用户点击行为进行建模。</li>
<li>FIM [31]：通过CNN网络从用户点击新闻和候选新闻的文本中匹配用户和新闻。</li>
<li>KRED [18]：通过图注意力网络从新闻中的实体及其在知识图中的邻居中学习新闻的表示。</li>
</ul>
<p></p>
<p>​	我们重复了五次不同的实验，并在表 2 中列出了不同方法的平均性能和相应的标准差。</p>
<ul>
<li>
<p>KIM 明显优于其他基准方法。</p>
<p>LSTUR、NRMS和KRED这些方法独立地对候选新闻和用户兴趣进行建模，而不考虑它们的相关性。这是因为用户可能对多个领域感兴趣，并且候选新闻也可能包含多个方面和实体。因此，这些方法很难准确匹配用户兴趣和候选新闻，因为它们是在这些方法中独立建模的。</p>
</li>
<li>
<p>KIM 还优于通过考虑候选新闻来建模用户兴趣的基线方法。</p>
<p>例如 DKN、DAN。这是因为候选新闻可能涵盖多个方面，而用户可能只对其中的一部分感兴趣[33、34]。然而，这些方法在没有考虑目标用户的情况下对候选新闻进行建模，这对于进一步将候选新闻与用户兴趣匹配可能较差。</p>
</li>
</ul>
<h3 id="消融实验">消融实验</h3>
<p>​	进行了两项消融研究来评估 KIM 的有效性。首先评估不同信息（即文本和知识）对新闻内容建模的有效性。</p>
<p></p>
<ul>
<li>首先，删除语义信息（即新闻文本）会严重损害 KIM 的性能。这是因为文本通常包含有关新闻内容的丰富信息，对于新闻内容的理解至关重要 [45]。去除语义信息会使新闻表示失去很多重要信息，并且不能准确地对新闻内容进行建模。</li>
<li>其次，在新闻内容建模中去除知识图谱（即知识知识图谱中的实体及其邻居）也会使 KIM 的性能显著下降。这是因为文本信息通常不足以理解新闻内容 [18, 32]。幸运的是，知识图谱包含不同实体之间的丰富关联。此外，用户点击新闻中的实体与候选新闻之间的相关性可以提供语义信息之外的丰富信息，以了解用户对候选新闻的兴趣。因此，将实体信息纳入个性化新闻推荐有可能提高推荐的准确性。</li>
</ul>
<p>​	接下来，我们通过分别用注意力网络替换它们来评估 KIM 中几个重要的注意力网络的有效性。</p>
<ul>
<li>首先，在用户新闻协同编码器中去除<strong>新闻关注网络</strong>后，KIM 的性能变得更差。这是因为用户兴趣可能是多样的，并且只有一部分用户点击的新闻对于建模用户兴趣和候选新闻之间的相关性是有用的[32]。此外，候选新闻内容可能包含多个方面，用户可能只对其中的一部分感兴趣。因此，通过新闻共同关注网络学习候选新闻感知用户兴趣和用户感知候选新闻表示可以更好地捕捉用户对候选新闻的兴趣。</li>
<li>其次，去除<strong>语义协同注意网络</strong>也会损害 KIM 的性能。这是因为点击新闻和候选新闻之间的语义相关性可以帮助理解用户对候选新闻的兴趣。此外，一条候选新闻或一条点击新闻通常包含多个方面，其中只有一部分对兴趣匹配有用。如果它们的语义信息是独立建模的，则很难在语义级别有效地捕捉点击新闻和候选新闻的相关性。因此，通过语义共同注意网络交互式学习点击新闻和候选新闻的基于语义的表示可以更好地捕捉它们之间的相关性，以便将用户兴趣与候选新闻匹配。</li>
<li>同时去除<strong>图协同注意力网络</strong>和<strong>实体协同注意力网络</strong>会导致 KIM 的性能下降。这是因为实体级别的点击新闻和候选新闻之间的相关性对于兴趣匹配也非常有用。此外，如果该方法独立地表示来自其实体的点击新闻和候选新闻，则对于兴趣匹配也是次优的。在KIM方法中，图协同注意力网络和实体协同注意力网络都用于以交互方式捕捉点击新闻和候选新闻实体之间的相关性，可以将丰富的信息融入KIM模型进行兴趣匹配。</li>
</ul>
<h2 id="结论">结论</h2>
<p>​	在本文中，我们提出了一种用于个性化新闻推荐的知识感知交互式匹配框架（命名为 KIM）。该框架旨在对候选新闻和用户兴趣进行交互建模，以实现更准确的兴趣匹配。更具体地说，我们首先提出了一个图协同注意网络，通过选择和聚合它们的邻居的信息来基于知识图对实体进行建模，这些信息为兴趣匹配提供了丰富的信息。我们还提出使用实体协同注意网络从实体之间的相关性中交互式地对点击新闻和候选新闻进行建模。此外，我们建议使用语义共同注意网络从文本之间的语义相关性中交互式地对点击新闻和候选新闻进行建模。此外，我们提出了一种用户新闻协同编码器来学习候选新闻感知用户表示和用户感知候选新闻表示，以更好地捕捉用户兴趣和候选新闻之间的相关性。我们对两个真实世界的数据集进行了广泛的实验。实验结果表明，我们的 KIM 方法显著优于其他基准方法。</p>
]]></description>
</item>
<item>
    <title>论文笔记——RMBERT: News Recommendation via Recurrent Reasoning Memory Network over BERT</title>
    <link>https://leeshy-tech.github.io/rmbert/</link>
    <pubDate>Mon, 23 May 2022 15:03:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/rmbert/</guid>
    <description><![CDATA[<h1 id="rmbert-news-recommendation-via-recurrent-reasoning-memory-network-over-bert">RMBERT: News Recommendation via Recurrent Reasoning Memory Network over BERT</h1>
<h2 id="论文概况">论文概况</h2>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3404835.3463234" target="_blank" rel="noopener noreffer">https://dl.acm.org/doi/abs/10.1145/3404835.3463234</a></p>
<p>SIGIR &lsquo;21: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</p>
<p>July 2021 Pages 1773–1777</p>
<p><a href="https://doi.org/10.1145/3404835.3463234" target="_blank" rel="noopener noreffer">https://doi.org/10.1145/3404835.3463234</a></p>
<h2 id="摘要">摘要</h2>
<p>​	现有的方法大多是根据新闻内容将每个用户和新闻分别编码为向量，然后对两个向量进行匹配。但是，用户对每个新闻或新闻的每个主题的兴趣可能是不同的。动态地学习用户和新闻向量，并对他们的互动进行建模是必要的。</p>
<p>​	在本研究中，我们提出了基于BERT的循环推理记忆网络(RMBERT)用于新闻推荐。与其他方法相比，我们的方法可以利用BERT的内容建模能力。此外，循环推理记忆网络执行一系列基于注意力的推理步骤，可以动态学习用户和新闻向量，并对每一步的交互进行建模。因此，我们的方法可以更好地模拟用户的兴趣。我们在真实世界的新闻推荐数据集上进行了广泛的实验，结果表明，我们的方法显著优于现有的最先进的方法。</p>
<h2 id="1-引言">1 引言</h2>
<p>​	最近，一些方法探索使用神经网络以端到端方式学习新闻和用户表示，并在训练过程中优化这些表示。DKN [13]， NPA [15]， LSTUR[1]提出使用CNN学习新闻表示，然后将候选新闻与用户点击的新闻进行匹配。DKN将知识图表示引入新闻推荐。NPA通过嵌入用户ID来关注重要词汇和新闻，增强了新闻和用户表示。LSTUR结合了长期和短期用户表示，以更精确地对用户进行建模。NRMS[16]引入多头自我注意学习新闻表示。FIM[12]通过叠加扩张卷积提取每个新闻的多层表示。</p>
<p>​	在新闻推荐场景中有两个常见的观察结果。首先，不同的用户可能对候选人新闻的不同部分感兴趣。第二，用户的兴趣通常是多样化的，用户历史中不同的新闻代表了该用户的不同兴趣。以前的工作 [9, 13, 16] 使用一个固定的嵌入向量来表示用户和新闻，这可能会限制模型的表达能力。作为一个解决方案，我们需要动态地确定关于候选新闻的用户向量。记忆网络能够捕获两个对象之间的高阶复杂关系，在问题回答[4,7]、情感分析[11]、机器理解[10]等领域都取得了很大的进展。受其成功的激励，我们设计了一个循环结构的迭代推理过程，多个推理记忆单元(RMC)级联执行结构化推理操作，一步一步确定匹配分数。</p>
<p>​	我们的方法的体系结构如图1所示。</p>
<ul>
<li>新闻编码器模块通过处理每个新闻的标题并生成新闻嵌入来提取候选新闻和一些用户点击的新闻。</li>
<li>在此之后，循环推理记忆网络中包含一些以新闻嵌入为输入的rmc，它们协同工作，逐级执行推理过程。在每一步中，RMC通过查询单元和存储单元进行推理操作。查询单元使用注意机制来选择用户可能感兴趣的候选新闻嵌入的某些方面来更新查询状态。所述存储单元根据查询状态，从用户点击的新闻嵌入中动态检索用户的兴趣。经过几个推理步骤后，RMBERT可以从多个方面捕获用户对候选新闻的偏好。</li>
<li>最后，我们根据最后的存储状态来推荐新闻，该状态包含了用户和候选新闻之间的交互信息。</li>
</ul>
<p></p>
<p>​	这项工作的主要贡献总结如下。</p>
<ol>
<li>我们使用BERT对候选新闻和用户点击新闻进行独立编码。我们的方法可以利用BERT的表达能力，同时获得离线预计算新闻嵌入的能力。</li>
<li>我们提出了一种循环结构来逐步执行基于注意力的推理操作。 在每个步骤中，RMC 可以推断候选新闻的某些部分与用户兴趣之间的匹配分数。 RMC可以在每一步动态确定新闻和用户向量，并在多方面探索它们的匹配。</li>
<li>从MSN新闻收集的真实数据集上进行的大量实验证实，我们的方法比现有的最先进的方法具有更好的性能。</li>
</ol>
<h2 id="2-提出的方法">2 提出的方法</h2>
<h3 id="21-新闻编码器">2.1 新闻编码器</h3>
<h3 id="22-推理存储单元">2.2 推理存储单元</h3>
]]></description>
</item>
<item>
    <title>网络实验——在linux平台安装OLSR协议</title>
    <link>https://leeshy-tech.github.io/network_olsr_with_mininet-wifi/</link>
    <pubDate>Sun, 27 Mar 2022 22:26:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/network_olsr_with_mininet-wifi/</guid>
    <description><![CDATA[<h1 id="在linux平台安装olsr协议">在linux平台安装OLSR协议</h1>
<h2 id="前言">前言</h2>
<p>因为要做一个OLSR和SDN自定义控制面的对比实验，所以要利用mininet-wifi平台自定义拓扑跑一下OLSR协议。</p>
<p>平台：ubuntu20.04</p>
<h2 id="安装">安装</h2>
<ul>
<li>
<p>官网：<a href="www.olsr.org/" rel="">www.olsr.org/</a></p>
</li>
<li>
<p>github：<a href="https://github.com/OLSR/olsrd" target="_blank" rel="noopener noreffer">https://github.com/OLSR/olsrd</a></p>
</li>
</ul>
<h3 id="通过mininet-wifi安装">通过mininet-wifi安装</h3>
<ul>
<li>进入mininet-wifi目录<code>sudo ./install.sh -o</code></li>
</ul>
<h3 id="从git安装没有亲自试来自网络">从git安装(没有亲自试，来自网络)</h3>
<ul>
<li>
<p>安装语法分析器：<code>sudo apt install bison flex</code></p>
</li>
<li>
<p>下载源码：<code>git clone https://github.com/OLSR/olsrd</code></p>
</li>
<li>
<p>编译：<code>cd olsrd;make</code></p>
</li>
<li>
<p>安装：<code>sudo make install</code></p>
</li>
</ul>
<h2 id="mininet-wifi拓扑构建">mininet-wifi拓扑构建</h2>
<blockquote>
<p>构造一个网络拓扑来测试OLSR协议。</p>
</blockquote>
<p>拓扑文件（参考example/adhoc.py）：</p>
<p><a href="https://github.com/leeshy-tech/mininet-wifi/blob/master/examples/OLSR/olsr_test.py" target="_blank" rel="noopener noreffer">https://github.com/leeshy-tech/mininet-wifi/blob/master/examples/OLSR/olsr_test.py</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="ch">#!/usr/bin/python</span>

<span class="s2">&#34;&#34;&#34;
</span><span class="s2">This example use four motionless station to test the OLSR protocol in adhoc network.
</span><span class="s2">It&#39;s almost the same as example/adhoc.py.
</span><span class="s2">use &#34;sudo python olsr_test.py olsrd&#34; in terminal to run it.
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">from</span> <span class="nn">mininet.log</span> <span class="kn">import</span> <span class="n">setLogLevel</span><span class="p">,</span> <span class="n">info</span>
<span class="kn">from</span> <span class="nn">mn_wifi.link</span> <span class="kn">import</span> <span class="n">wmediumd</span><span class="p">,</span> <span class="n">adhoc</span>
<span class="kn">from</span> <span class="nn">mn_wifi.manetRoutingProtocols</span> <span class="kn">import</span> <span class="n">olsrd</span>
<span class="kn">from</span> <span class="nn">mn_wifi.cli</span> <span class="kn">import</span> <span class="n">CLI</span>
<span class="kn">from</span> <span class="nn">mn_wifi.net</span> <span class="kn">import</span> <span class="n">Mininet_wifi</span>
<span class="kn">from</span> <span class="nn">mn_wifi.wmediumdConnector</span> <span class="kn">import</span> <span class="n">interference</span>


<span class="k">def</span> <span class="nf">topology</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="s2">&#34;Create a network.&#34;</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Mininet_wifi</span><span class="p">(</span><span class="n">link</span><span class="o">=</span><span class="n">wmediumd</span><span class="p">,</span> <span class="n">wmediumd_mode</span><span class="o">=</span><span class="n">interference</span><span class="p">)</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Creating nodes</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">if</span> <span class="s1">&#39;-a&#39;</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;range&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>

    <span class="n">sta1</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">addStation</span><span class="p">(</span><span class="s1">&#39;sta1&#39;</span><span class="p">,</span> <span class="n">ip6</span><span class="o">=</span><span class="s1">&#39;fe80::1&#39;</span><span class="p">,</span><span class="n">position</span><span class="o">=</span><span class="s1">&#39;25,50,0&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">sta2</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">addStation</span><span class="p">(</span><span class="s1">&#39;sta2&#39;</span><span class="p">,</span> <span class="n">ip6</span><span class="o">=</span><span class="s1">&#39;fe80::2&#39;</span><span class="p">,</span><span class="n">position</span><span class="o">=</span><span class="s1">&#39;75,10,0&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">sta3</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">addStation</span><span class="p">(</span><span class="s1">&#39;sta3&#39;</span><span class="p">,</span> <span class="n">ip6</span><span class="o">=</span><span class="s1">&#39;fe80::3&#39;</span><span class="p">,</span><span class="n">position</span><span class="o">=</span><span class="s1">&#39;75,90,0&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">sta4</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">addStation</span><span class="p">(</span><span class="s1">&#39;sta4&#39;</span><span class="p">,</span> <span class="n">ip6</span><span class="o">=</span><span class="s1">&#39;fe80::4&#39;</span><span class="p">,</span><span class="n">position</span><span class="o">=</span><span class="s1">&#39;125,50,0&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">net</span><span class="o">.</span><span class="n">setPropagationModel</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&#34;logDistance&#34;</span><span class="p">,</span> <span class="n">exp</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Configuring wifi nodes</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">configureWifiNodes</span><span class="p">()</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Creating links</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="c1"># MANET routing protocols supported by proto:</span>
    <span class="c1"># babel, batman_adv, batmand and olsr</span>
    <span class="c1"># WARNING: we may need to stop Network Manager if you want</span>
    <span class="c1"># to work with babel</span>
    <span class="n">protocols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;babel&#39;</span><span class="p">,</span> <span class="s1">&#39;batman_adv&#39;</span><span class="p">,</span> <span class="s1">&#39;batmand&#39;</span><span class="p">,</span> <span class="s1">&#39;olsrd&#39;</span><span class="p">,</span> <span class="s1">&#39;olsrd2&#39;</span><span class="p">]</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">proto</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">proto</span> <span class="ow">in</span> <span class="n">protocols</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;proto&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">proto</span>

    <span class="n">net</span><span class="o">.</span><span class="n">addLink</span><span class="p">(</span><span class="n">sta1</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">adhoc</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s1">&#39;sta1-wlan0&#39;</span><span class="p">,</span>
                <span class="n">ssid</span><span class="o">=</span><span class="s1">&#39;adhocNet&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">ht_cap</span><span class="o">=</span><span class="s1">&#39;HT40+&#39;</span><span class="p">,</span>  <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">addLink</span><span class="p">(</span><span class="n">sta2</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">adhoc</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s1">&#39;sta2-wlan0&#39;</span><span class="p">,</span>
                <span class="n">ssid</span><span class="o">=</span><span class="s1">&#39;adhocNet&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">ht_cap</span><span class="o">=</span><span class="s1">&#39;HT40+&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">addLink</span><span class="p">(</span><span class="n">sta3</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">adhoc</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s1">&#39;sta3-wlan0&#39;</span><span class="p">,</span>
                <span class="n">ssid</span><span class="o">=</span><span class="s1">&#39;adhocNet&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">ht_cap</span><span class="o">=</span><span class="s1">&#39;HT40+&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">addLink</span><span class="p">(</span><span class="n">sta4</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">adhoc</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s1">&#39;sta4-wlan0&#39;</span><span class="p">,</span>
                <span class="n">ssid</span><span class="o">=</span><span class="s1">&#39;adhocNet&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">ht_cap</span><span class="o">=</span><span class="s1">&#39;HT40+&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">net</span><span class="o">.</span><span class="n">plotGraph</span><span class="p">(</span><span class="n">max_x</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">max_y</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Starting network</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">*** Addressing...</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">&#39;proto&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">sta1</span><span class="o">.</span><span class="n">setIP6</span><span class="p">(</span><span class="s1">&#39;2001::1/64&#39;</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s2">&#34;sta1-wlan0&#34;</span><span class="p">)</span>
        <span class="n">sta2</span><span class="o">.</span><span class="n">setIP6</span><span class="p">(</span><span class="s1">&#39;2001::2/64&#39;</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s2">&#34;sta2-wlan0&#34;</span><span class="p">)</span>
        <span class="n">sta3</span><span class="o">.</span><span class="n">setIP6</span><span class="p">(</span><span class="s1">&#39;2001::3/64&#39;</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s2">&#34;sta3-wlan0&#34;</span><span class="p">)</span>
        <span class="n">sta4</span><span class="o">.</span><span class="n">setIP6</span><span class="p">(</span><span class="s1">&#39;2001::4/64&#39;</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s2">&#34;sta4-wlan0&#34;</span><span class="p">)</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Running CLI</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">CLI</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Stopping network</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">setLogLevel</span><span class="p">(</span><span class="s1">&#39;info&#39;</span><span class="p">)</span>
    <span class="n">topology</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>
</code></pre></div><p>可视化：</p>
<p></p>
<p>解读：</p>
<p>从图中可以看出，sta1只能与sta2和sta3进行单跳通信，如果要与sta4通信，就需要sta2或者sta3进行中继。如果没有OLSR协议，节点在收到目的IP不是本节点的包之后就会丢掉，无法完成中继。OLSR协议会在网络中的节点维护整个网络拓扑，就能完成中继。</p>
<h2 id="实验测试">实验测试</h2>
<h3 id="关闭networkmanager">关闭NetworkManager</h3>
<p><code>sudo systemctl stop NetworkManager</code></p>
<p>NetworkManager是linux的自动网络配置工具，我们希望自己配置网络，所以要把它关掉。</p>
<p>查看节点的网络状态<code>ip addr</code>，没有图中的<code>NO-CARRIER</code>说明NetworkManager已经被关闭。（这个命令可以在本机运行，也可以在mininet虚拟主机运行。）</p>
<p></p>
<h3 id="配置olsr">配置OLSR</h3>
<p>编辑配置文件：<code>vim /etc/olsrd/olsrd.conf</code></p>
<p>添加所有节点的网卡：</p>
<p></p>
<p>退出、保存</p>
<h3 id="运行拓扑文件">运行拓扑文件</h3>
<p><code>sudo python olsr_test.py olsrd</code></p>
<p></p>
<h3 id="网络测试">网络测试</h3>
<p><code>sta1 ping sta4</code></p>
<p></p>
<p>能ping通，说明OLSR协议运行正常。</p>
<p>查看路由：<code>sta3 route</code></p>
<p></p>
<p>多了三条路由，这是OLSR协议运行的结果。</p>
<h2 id="结束">结束</h2>
<h3 id="恢复系统">恢复系统</h3>
<p>开启NetworkManager：<code>sudo systemctl start NetworkManager</code></p>
<p>退出mininet-wifi：<code>exit</code></p>
<p>清理系统：<code>sudo mn -c</code></p>
<h3 id="参考文献">参考文献</h3>
<p><a href="https://blog.csdn.net/whatday/article/details/106096127" target="_blank" rel="noopener noreffer">centos7 开启 关闭 NetworkManager</a></p>
<p><a href="https://blog.csdn.net/qq_35109869/article/details/79839357" target="_blank" rel="noopener noreffer">Linux虚拟机下OLSR协议的安装</a></p>
<p><a href="https://github.com/intrig-unicamp/mininet-wifi/issues/342" target="_blank" rel="noopener noreffer">Unable to create IPv6 multi hop mesh network in ad hoc mode #342</a>这个issue救了大命了</p>
<p><a href="https://blog.csdn.net/weixin_29279047/article/details/116832580" target="_blank" rel="noopener noreffer">Linux卸载olsrd,olsrd路由协议移植到嵌入式linux中使用</a></p>
<p><a href="www.olsr.org/" rel="">www.olsr.org/</a>官网写的说明太少了，根本看不懂，麻了。</p>
<p><a href="https://github.com/OLSR/olsrd" target="_blank" rel="noopener noreffer">https://github.com/OLSR/olsrd</a></p>
]]></description>
</item>
<item>
    <title>Linux——图片url生成</title>
    <link>https://leeshy-tech.github.io/linux_image_url/</link>
    <pubDate>Thu, 17 Mar 2022 20:45:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/linux_image_url/</guid>
    <description><![CDATA[<h1 id="图片url生成">图片url生成</h1>
<h2 id="准备">准备</h2>
<h3 id="安装jdkjre">安装JDK，JRE</h3>
<ul>
<li>
<p>下载linux的jdk，jre压缩包：</p>
<ul>
<li><a href="https://www.oracle.com/java/technologies/downloads/#java8" target="_blank" rel="noopener noreffer">https://www.oracle.com/java/technologies/downloads/#java8</a></li>
<li>用xftp传到服务器上。</li>
<li>解压<code>tar -zxvf jdk-17_linux-x64_bin.tar.gz jre-8u321-linux-x64.tar.gz</code>，记住此时所在的路径（pwd命令可查）。</li>
</ul>
</li>
<li>
<p>配置环境变量：</p>
<ul>
<li>
<p><code>cd /etc</code></p>
</li>
<li>
<p><code>vim profile</code></p>
</li>
<li>
<p>i进入编辑模式</p>
</li>
<li>
<p>文件末尾加上如下代码，JAVA_HOME,JRE_HOME分别为解压的文件夹的路径：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">export</span> <span class="nv">JAVA_HOME</span><span class="o">=</span>/home/ubuntu/jdk-17.0.2
<span class="nb">export</span> <span class="nv">JRE_HOME</span><span class="o">=</span>/home/ubuntu/jre1.8.0_321
<span class="nb">export</span> <span class="nv">CLASSPATH</span><span class="o">=</span>.:<span class="nv">$JAVA_HOME</span>/lib:<span class="nv">$JRE_HOME</span>/lib
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$JAVA_HOME</span>/bin:<span class="nv">$PATH</span>
</code></pre></div></li>
<li>
<p><code>Esc</code>退出，输入<code>:wq</code>保存退出。</p>
</li>
</ul>
</li>
<li>
<p>使能配置：<code>source /etc/profile</code></p>
</li>
<li>
<p>检验：<code>java -version</code>，输出版本信息，安装成功。</p>
</li>
</ul>
<h3 id="安装tomcat">安装tomcat</h3>
<ul>
<li>
<p>下载安装包：</p>
<ul>
<li>
<p><a href="https://tomcat.apache.org/download-10.cgi" target="_blank" rel="noopener noreffer">https://tomcat.apache.org/download-10.cgi</a></p>
<p></p>
</li>
<li>
<p>用xftp传到服务器上，解压<code>tar -zxvf apache-tomcat-10.0.18.tar.gz</code></p>
</li>
</ul>
</li>
<li>
<p>进入bin目录，启动tomcat</p>
<ul>
<li>
<p><code>cd apache-tomcat-10.0.18/bin</code></p>
</li>
<li>
<p><code>./startup.sh</code></p>
<p></p>
</li>
</ul>
</li>
</ul>
<h3 id="防火墙设置">防火墙设置</h3>
<p>到服务器控制台，开启8080端口：</p>
<p></p>
<p>浏览器访问<code>服务器IP:8080</code>地址，看到tomcat默认页说明tomcat安装运行成功。</p>
<p></p>
<h2 id="生成图片url">生成图片url</h2>
<ul>
<li>
<p>假设图片存放在服务器路径：<code>/home/ubuntu/image</code></p>
</li>
<li>
<p>进入tomcat文件夹的conf路径，编辑server.xml：</p>
<ul>
<li>
<p><code>cd conf</code></p>
</li>
<li>
<p><code>vim server.xml</code></p>
</li>
<li>
<p>结尾处插入此代码<code>&lt;Context docBase=&quot;/home/ubuntu/image&quot; path=&quot;/pictures&quot; debug=&quot;0&quot; reloadable=&quot;true&quot;/&gt;</code></p>
<p></p>
</li>
</ul>
</li>
</ul>
<p>则可以通过<code>url=http://ip:8080/path/图片名+后缀</code>访问该图片。</p>
<p></p>
<h2 id="结束语">结束语</h2>
<h3 id="参考文献">参考文献</h3>
<p><a href="https://www.bilibili.com/video/BV1uh411a7Jg?p=268" target="_blank" rel="noopener noreffer">https://www.bilibili.com/video/BV1uh411a7Jg?p=268</a></p>
<p><a href="https://blog.csdn.net/dyt443733328/article/details/102587168" target="_blank" rel="noopener noreffer">tomcat启动“成功”，但是浏览器无法访问</a></p>
<p><a href="https://blog.csdn.net/Wyx_wx/article/details/89117746" target="_blank" rel="noopener noreffer">访问 Linux 服务器上的文件（以图片为例</a></p>
]]></description>
</item>
<item>
    <title>Ryu——安装</title>
    <link>https://leeshy-tech.github.io/ryu_install/</link>
    <pubDate>Mon, 07 Mar 2022 21:41:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/ryu_install/</guid>
    <description><![CDATA[<h1 id="ryu安装">Ryu安装</h1>
<h2 id="安装git">安装git</h2>
<p><code>sudo apt install git</code></p>
<h2 id="安装python3">安装python3</h2>
<blockquote>
<p>时代变了，不装不行。</p>
</blockquote>
<ul>
<li>
<p>下载</p>
<p><code>sudo apt install python3</code></p>
</li>
<li>
<p>查看python3的位置和版本号，用于第四步</p>
<p><code>whereis python3</code></p>
</li>
<li>
<p>删除原来python2的软连接</p>
<p><code>sudo rm /usr/bin/python</code></p>
</li>
<li>
<p>建立新的软连接</p>
<p><code>sudo ln -s /usr/bin/python3.9 /usr/bin/python</code></p>
</li>
<li>
<p>查看版本</p>
<p><code>python --version</code></p>
</li>
</ul>
<h2 id="安装ryu">安装Ryu</h2>
<ul>
<li>
<p>更新pip</p>
<p><code>sudo pip install --upgrade pip</code></p>
</li>
<li>
<p>克隆源代码</p>
<p><code>git clone git://github.com/faucetsdn/ryu.git</code></p>
</li>
<li>
<p>进入ryu目录</p>
<p><code>cd ryu</code></p>
</li>
<li>
<p>安装依赖</p>
<p><code>sudo pip install -r tools/pip-requires</code></p>
</li>
<li>
<p>安装ryu</p>
<p><code>sudo python setup.py install</code></p>
</li>
</ul>
<h2 id="测试">测试</h2>
<ul>
<li>
<p>进入ryu/ryu/app目录</p>
<p><code>cd ryu/ryu/app</code></p>
</li>
<li>
<p>运行simple_switch.py</p>
<p><code>ryu-manager app/simple_switch.py</code></p>
<p>出现以下输出为正常：</p>
<pre tabindex="0"><code>loading app app/simple_switch.py
loading app ryu.controller.ofp_handler
instantiating app app/simple_switch.py of SimpleSwitch
instantiating app ryu.controller.ofp_handler of OFPHandler
</code></pre></li>
</ul>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/sexyluna/article/details/105740519" target="_blank" rel="noopener noreffer">Ubuntu将默认python版本改为python3</a></p>
<p><a href="https://github.com/leeshy-tech/ryu" target="_blank" rel="noopener noreffer">https://github.com/leeshy-tech/ryu</a></p>
]]></description>
</item>
<item>
    <title>install mysql on linux</title>
    <link>https://leeshy-tech.github.io/mysql_install/</link>
    <pubDate>Mon, 07 Mar 2022 20:53:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/mysql_install/</guid>
    <description><![CDATA[<h1 id="install-mysql-on-linux">install mysql on linux</h1>
<h2 id="安装">安装：</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">sudo apt update
sudo apt install mysql-server
</code></pre></div><h2 id="配置root密码为123456">配置root密码为123456：</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">sudo mysql
use mysql<span class="p">;</span>
update user <span class="nb">set</span> <span class="nv">authentication_string</span><span class="o">=</span><span class="s1">&#39;&#39;</span> where <span class="nv">user</span><span class="o">=</span><span class="s1">&#39;root&#39;</span><span class="p">;</span>
alter user <span class="s1">&#39;root&#39;</span>@<span class="s1">&#39;localhost&#39;</span> identified with mysql_native_password by <span class="s1">&#39;123456&#39;</span><span class="p">;</span>
</code></pre></div><h2 id="参考文献">参考文献：</h2>
<p><a href="https://blog.csdn.net/qq_26164609/article/details/106881079" target="_blank" rel="noopener noreffer">Ubunto20.04安装MySQL并修改root用户密码</a></p>
<p><a href="https://developer.aliyun.com/article/758177" target="_blank" rel="noopener noreffer">如何在 Ubuntu 20.04 上安装 MySQL</a></p>
]]></description>
</item>
<item>
    <title>mininet-wifi——安装</title>
    <link>https://leeshy-tech.github.io/mininet-wifi_install/</link>
    <pubDate>Mon, 07 Mar 2022 20:53:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/mininet-wifi_install/</guid>
    <description><![CDATA[<h1 id="安装mininet-wifi">安装mininet-wifi</h1>
<p>mininet学了快半年了，还是安装七八次才能装上，人麻了，怒写一篇博客。平台：Ubuntu20.04。</p>
<h2 id="安装git">安装git</h2>
<p><code>sudo apt install git</code></p>
<h2 id="安装python3">安装python3</h2>
<p>mininet在python2和python3环境下都是能正常运行的，但是，apt中一些python2的包已经升级到3了，比如python-matplotlib，你不升级python3，mininet-wifi就会安装它，但是apt里又没有，只会一直报错。你再怎么更新源，也找不到这个玩意，因为它已经变成python3-matplotlib了。所以还是要安装python3。</p>
<ul>
<li>
<p>下载</p>
<p><code>sudo apt install python3</code></p>
</li>
<li>
<p>查看python3的位置和版本号，用于第四步</p>
<p><code>whereis python3</code></p>
</li>
<li>
<p>删除原来python2的软连接</p>
<p><code>sudo rm /usr/bin/python</code></p>
</li>
<li>
<p>建立新的软连接</p>
<p><code>sudo ln -s /usr/bin/python3.9 /usr/bin/python</code></p>
</li>
<li>
<p>查看版本</p>
<p><code>python --version</code></p>
</li>
</ul>
<h2 id="安装mininet-wifi-1">安装mininet-wifi</h2>
<h3 id="有梯子或者有git代理">有梯子，或者有git代理</h3>
<ul>
<li>
<p>克隆源代码</p>
<p><code>git clone https://github.com/intrig-unicamp/mininet-wifi</code></p>
</li>
<li>
<p>查看安装可选项</p>
<p><code>sudo mininet-wifi/util/install.sh -h</code></p>
</li>
<li>
<p>选择一些项安装（默认就按这个）</p>
<p><code>sudo mininet-wifi/util/install.sh -Wlnfv</code></p>
</li>
</ul>
<h3 id="无代理">无代理</h3>
<p>这里主要是指以https无法正常访问github的情况，需要把所有的git网址改为git://开头，因为install.sh里会有下载其他库的git命令，所以直接运行install.sh会报git超时，需要提前把相关库下好。</p>
<ul>
<li>
<p>克隆</p>
<p><code>git clone git://github.com/intrig-unicamp/mininet-wifi</code></p>
<p><code>git clone git://github.com/ramonfontes/mac80211_hwsim_mgmt</code></p>
<p><code>git clone git://github.com/mininet/mininet</code></p>
<p><code>git clone git://github.com/vchakour/wmediumd</code></p>
</li>
<li>
<p>选择一些项安装（默认就按这个）</p>
<p><code>sudo mininet-wifi/util/install.sh -Wlnfv</code></p>
</li>
</ul>
<h2 id="运行">运行</h2>
<ul>
<li>
<p>运行，这句正常运行就说明下载成功。</p>
<p><code>sudo mn --wifi</code></p>
</li>
<li>
<p>退出</p>
<p><code>exit</code></p>
</li>
<li>
<p>清理</p>
<p><code>sudo mn -c</code></p>
</li>
</ul>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://github.com/intrig-unicamp/mininet-wifi" target="_blank" rel="noopener noreffer">https://github.com/intrig-unicamp/mininet-wifi</a></p>
<p><a href="https://blog.csdn.net/sexyluna/article/details/105740519" target="_blank" rel="noopener noreffer">Ubuntu将默认python版本改为python3</a></p>
]]></description>
</item>
</channel>
</rss>
