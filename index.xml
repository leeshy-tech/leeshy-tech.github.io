<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Leeshy&#39;s Blog | To be humble</title>
        <link>https://leeshy-tech.github.io/</link>
        <description>Welcome to Leeshy&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>saili@bupt.edu.cn (Leeshy)</managingEditor>
            <webMaster>saili@bupt.edu.cn (Leeshy)</webMaster><lastBuildDate>Sun, 31 Jul 2022 21:49:06 &#43;0800</lastBuildDate>
            <atom:link href="https://leeshy-tech.github.io/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>考研</title>
    <link>https://leeshy-tech.github.io/goodbye/</link>
    <pubDate>Sun, 31 Jul 2022 21:49:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/goodbye/</guid>
    <description><![CDATA[<h1 id="考研">考研</h1>
<p>从2022/07/02正式开始准备考研了，到考研结束之前应该不会再对博客进行更新了。</p>
<p>此贴记录一些flag，考研结束之后挨个做。</p>
<p>也许这些东西对复试也会有点帮助？</p>
<h2 id="新博客">新博客</h2>
<p>这个博客主题是照着lgt的搭的，其实当时也不是很想照搬别人的博客，但是主题看来看去都看不入眼，很喜欢这种简洁风格。但是没想到cl大师和maxlinn同学也是feellt主题，有丝分裂了属于是，等考研结束就换一个。</p>
<h2 id="课程记录">课程记录</h2>
<p>本科的一些课程还是下了很多功夫的，之后简单写个贴记录一下。</p>
<h3 id="数字系统设计实验">数字系统设计实验</h3>
<p>虽然数电学的很垃圾（主要是打那个破物理比赛去了），但是数电实验当时确实下了很多功夫，当时不仅完成了所有要求，还做了个lcd屏的显示（参考<a href="https://www.cnblogs.com/Clouds42/p/11938079.html" target="_blank" rel="noopener noreffer">https://www.cnblogs.com/Clouds42/p/11938079.html</a>），美中不足的是代码没组织好，模块分的不够清楚。</p>
<h3 id="信息网络建模与仿真">信息网络建模与仿真</h3>
<p>这部分代码已经传到github上好久了，一直偷懒没写东西，这门课的随机数和随机过程生成的相关知识挺有用的。</p>
<h3 id="模式识别及应用">模式识别及应用</h3>
<p>这门课基于老师的数据集Oracle-MNIST做了一些模型的实践，主要是《动手学深度学习》这本书的例子改的，也写一些东西吧。</p>
<h3 id="信息系统设计">信息系统设计</h3>
<p>这门课做了后端、鸿蒙软件和硬件的开发，写一些东西把自己做的东西理一理。</p>
<h2 id="考研总结">考研总结</h2>
<p>要是成功了就是经验贴，要是没成功就是教训贴。</p>
<p>可能会写个日记，定期push到github上。</p>
]]></description>
</item>
<item>
    <title>论文笔记——OpenFlow: Enabling Innovation in Campus Networks</title>
    <link>https://leeshy-tech.github.io/openflow/</link>
    <pubDate>Tue, 28 Jun 2022 17:30:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/openflow/</guid>
    <description><![CDATA[<h1 id="openflow-enabling-innovation-in-campus-networks">OpenFlow: Enabling Innovation in Campus Networks</h1>
<p>OpenFlow：实现校园网络的创新</p>
<h2 id="论文概况">论文概况</h2>
<p><a href="https://dl.acm.org/toc/sigcomm-ccr/2008/38/2" target="_blank" rel="noopener noreffer">ACM SIGCOMM Computer Communication Review</a><a href="https://dl.acm.org/toc/sigcomm-ccr/2008/38/2" target="_blank" rel="noopener noreffer">Volume 38</a><a href="https://dl.acm.org/toc/sigcomm-ccr/2008/38/2" target="_blank" rel="noopener noreffer">Issue 2</a></p>
<p>April 2008 pp 69–74</p>
<p>自翻：<a href="https://github.com/leeshy-tech/PaperTranslate/blob/main/OpenFlow.md" target="_blank" rel="noopener noreffer">https://github.com/leeshy-tech/PaperTranslate/blob/main/OpenFlow.md</a></p>
<h2 id="摘要">摘要</h2>
<p>本白皮书提出了 OpenFlow：一种供研究人员在他们每天使用的网络中运行实验协议的方法。 OpenFlow 基于以太网交换机，具有内部流表和用于添加和删除流条目的标准化接口。我们的目标是鼓励网络供应商将 OpenFlow 添加到他们的交换机产品中，以部署在大学校园骨干网和配线间中。我们认为 OpenFlow 是一种务实的折衷方案：一方面，它允许研究人员以统一的方式以线速和高端口密度在异构交换机上运行实验；另一方面，供应商不需要公开其交换机的内部工作原理。除了允许研究人员在现实世界的流量设置中评估他们的想法外，OpenFlow 还可以作为一个有用的校园组件，用于提议的大规模测试平台（如 GENI）。斯坦福大学的两座建筑物将很快使用商用以太网交换机和路由器运行 OpenFlow 网络。我们将努力鼓励在其他学校部署；我们鼓励您也考虑在您的大学网络中部署 OpenFlow。</p>
<h2 id="1-对可编程网络的需求">1. 对可编程网络的需求</h2>
<p>今天，几乎没有实用的方法可以在足够现实的环境（例如，大规模承载真实流量）中试验新的网络协议（例如，新的路由协议或 IP 的替代方案）以获得广泛部署所需的信心。 结果是来自网络研究社区的大多数新想法都未经尝试和测试。 因此，人们普遍认为网络基础设施已经“僵化”。</p>
<p>认识到这个问题后，网络社区正在努力开发可编程网络，例如 GENI [1]，这是一个提议的全国性研究机构，用于试验新的网络架构和分布式系统。 这些可编程网络需要可编程交换机和路由器（使用虚拟化）可以同时处理多个隔离实验网络的数据包。</p>
<p>虚拟化可编程网络可以降低新想法的进入门槛，提高网络基础设施的创新速度。 但全国性设施的计划雄心勃勃（而且成本高昂），部署起来需要数年时间。 本白皮书关注一个离家更近的短期问题：作为研究人员，我们如何在校园网络中进行实验？ 如果我们能弄清楚这个问题，我们可以很快开始并将该技术扩展到其他校园，以造福整个社区。</p>
<p>我们的目标是提出一种新的交换机功能，可以帮助将可编程性扩展到大学校园的配线间。</p>
<ul>
<li>
<p>一种我们不采用的方法是说服商业设备供应商在他们的交换机和路由器上提供一个开放的、可编程的、虚拟化平台，以便研究人员可以部署新协议，而网络管理员不用担心设备的支持问题。这种结果在短期内不太可能发生。</p>
</li>
<li>
<p>一些开放的软件平台已经存在，但没有我们需要的性能或端口密度。</p>
</li>
<li>
<p>具有用于线速处理的专用硬件的现有平台也不太适合大学布线室。</p>
</li>
</ul>
<p>因此，商业解决方案过于封闭和不灵活，研究解决方案要么性能不足或扇出，要么过于昂贵。具有完全通用性的研究解决方案似乎不太可能克服其性能或成本限制。一种更有希望的方法是在通用性上妥协并寻求一定程度的开关灵活性，即：</p>
<ul>
<li>适合高性能和低成本的实施。</li>
<li>能够支持广泛的研究。</li>
<li>确保将实验流量与生产流量隔离开来。</li>
<li>符合供应商对封闭平台的需求。</li>
</ul>
<p>本文描述了 OpenFlow 交换机 — 一种最初尝试满足这四个目标的规范。</p>
<h2 id="2-openflow交换机">2. OpenFlow交换机</h2>
<p>基本思想很简单：我们利用大多数现代以太网交换机和路由器包含以线速运行的流表（通常由 TCAM 构建）来实现防火墙、NAT、QoS 和收集统计数据。虽然每个供应商的流表都不同，但我们已经确定了一组有趣的通用功能，可在许多交换机和路由器中运行。</p>
<p>OpenFlow 利用了这组通用功能。 OpenFlow 提供了一个开放协议来对不同交换机和路由器中的流表进行编程。网络管理员可以将流量划分为生产和研究流。研究人员可以通过选择他们的数据包遵循的路线和他们接收的处理来控制他们自己的流量。通过这种方式，研究人员可以尝试新的路由协议、安全模型、寻址方案，甚至是 IP 的替代方案。在同一个网络上，生产流量被隔离并以与今天相同的方式进行处理。</p>
<p>OpenFlow 交换机的数据路径由流表和与每个流条目关联的操作组成。 OpenFlow 交换机支持的操作集是可扩展的，但下面我们描述了所有交换机的最低要求。为了实现高性能和低成本，数据路径必须具有精心规定的灵活性。这意味着放弃指定任意处理每个数据包的能力，并寻求更有限但仍然有用的操作范围。因此，在本文后面，为所有 OpenFlow 交换机定义一组基本的必需操作。</p>
<p>一个 OpenFlow 交换机至少由三部分组成：（1）流表，与每个流条目相关联的动作，用于告诉交换机如何处理流，（2）将交换机连接到远程控制程序（称为控制器）的安全通道，它在控制器和交换机之间发送命令和数据包，使用 (3) OpenFlow 协议，该协议为控制器与交换机通信提供了一种开放和标准的方式。 通过指定一个标准接口（开放流协议），流表中的条目可以通过该接口在外部定义，开放流交换机避免了研究人员对交换机进行编程的需要。</p>
<p><strong>专用OpenFlow交换机。</strong> 专用 OpenFlow 交换机是在端口之间转发数据包的哑数据路径元素，由远程控制程序定义。 图 1 显示了 OpenFlow 交换机的示例。</p>
<p></p>
<p>在这种情况下，流被广泛定义，并且仅受流表的特定实现的能力的限制。 例如，一个流可以是一个 TCP 连接，或来自特定 MAC 地址或 IP 地址的所有数据包，或具有相同 VLAN 标记的所有数据包，或来自同一交换机端口的所有数据包。 对于涉及非 IPv4 数据包的实验，可以将流定义为与特定（但非标准）标头匹配的所有数据包。</p>
<p>每个流条目都有一个与之关联的简单动作； 三个基本的（所有专用 OpenFlow 交换机都必须支持）是：</p>
<ol>
<li>将此流的数据包转发到给定端口（或多个端口）。 这允许数据包通过网络进行路由。 在大多数交换机中，这预计将在线性速率下发生。</li>
<li>封装此流的数据包并将其转发给控制器。 数据包被传递到安全通道，在那里它被封装并发送到控制器。 通常用于新流中的第一个数据包，因此控制器可以决定是否应将流添加到流表中。 或者在某些实验中，它可以用于将所有数据包转发到控制器进行处理。</li>
<li>丢弃该流的数据包。 可用于安全、遏制拒绝服务攻击或减少来自终端主机的虚假广播发现流量。</li>
</ol>
<p>Flow-Table 中的条目具有三个字段：（1）定义流的数据包头，（2）定义应如何处理数据包的操作，以及（3）统计数据，跟踪数据包的数量。 每个流的数据包和字节，以及自最后一个数据包与流匹配的时间（以帮助删除非活动流）。</p>
<p>在第一代“Type 0”交换机中，流标头是一个 10 元组，如表 1 所示。TCP 流可以由所有十个字段指定，而 IP 流可能不包括其定义中的传输端口。 每个标头字段可以是通配符，以允许聚合流，例如仅定义 VLAN ID 的流将应用于特定 VLAN 上的所有流量。</p>
<p></p>
<p><strong>OpenFlow使能的交换机。</strong> 一些商用交换机、路由器和接入点将通过添加流表、安全通道和 OpenFlow 协议来增强 OpenFlow 功能（我们在第 5 节中列出了一些示例）。 通常，流表将重用现有硬件，例如 TCAM； 安全通道和协议将被移植以在交换机的操作系统上运行。 图 2 显示了支持 OpenFlow 的商业交换机和接入点网络。 在这个例子中，所有的流表都由同一个控制器管理； OpenFlow 协议允许交换机由两个或多个控制器控制，以提高性能或鲁棒性。</p>
<p></p>
<p>我们的目标是使实验能够在现有的生产网络中与常规流量和应用程序一起进行。 因此，为了赢得网络管理员的信任，启用 OpenFlow 的交换机必须将实验流量（由 Flow Table 处理）与将由交换机的正常第 2 层和第 3 层管道处理的生产流量隔离开来。 有两种方法可以实现这种分离。 一种是添加第四个动作：</p>
<ol start="4">
<li>通过交换机的正常处理管道转发此流的数据包。</li>
</ol>
<p>另一种是为实验和生产流量定义单独的 VLAN 集。 这两种方法都允许交换机以通常的方式处理不属于实验的正常生产流量。 所有启用 OpenFlow 的交换机都需要支持一种方法或另一种方法； 有些人会同时支持两者。</p>
<p><strong>额外的特性。</strong> 如果交换机支持报头格式和上面提到的四个基本操作（在 OpenFlow 交换机规范中有详细说明），那么我们称其为“Type 0”交换机。 我们预计许多交换机将支持其他操作，例如重写部分数据包头（例如，用于 NAT，或混淆中间链路上的地址），并将数据包映射到优先级类别。 同样，一些流表将能够匹配数据包头中的任意字段，从而可以使用新的非 IP 协议进行实验。 随着一组特定功能的出现，我们将定义一个“Type 1”开关。</p>
<p><strong>控制器。</strong> 控制器代表实验从流表中添加和删除流条目。 例如，静态控制器可能是在 PC 上运行的简单应用程序，用于在实验期间静态建立流以互连一组测试计算机。 在这种情况下，流类似于当前网络中的 VLAN——提供一种简单的机制来将实验流量与生产网络隔离。 从这个角度来看，OpenFlow 是 VLAN 的泛化。</p>
<p>人们还可以想象更复杂的控制器，它们会随着实验的进行动态地添加/删除流。 在一个使用模型中，研究人员可以控制整个 OpenFlow 交换机网络，并可以自由决定如何处理所有流。 更复杂的控制器可能支持多个研究人员，每个研究人员具有不同的帐户和权限，使他们能够在不同的流程集上运行多个独立的实验。 识别为在特定研究人员控制下的流（例如，通过在控制器中运行的策略表）可以传送到研究人员的用户级控制程序，然后由该程序决定是否应将新的流条目添加到交换机网络 .</p>
<h2 id="3-使用openflow">3. 使用OpenFlow</h2>
<p>例子略</p>
<p>关于随着实验的进行动态添加和删除流的控制器的性能、可靠性和可扩展性，有一些合理的问题要问：这样的集中式控制器能否足够快地处理新流和对流开关进行编程？当控制器发生故障时会发生什么？在某种程度上，这些问题在 Ethane 原型的背景下得到解决，该原型使用简单的流量交换机和中央控制器 [7]。初步结果表明，基于低成本台式 PC 的 Ethane 控制器每秒可以处理超过 10,000 个新流量，足以满足大型大学校园的需求。当然，新流的处理速度将取决于研究人员实验所需的处理复杂性。但这让我们相信可以进行有意义的实验。通过使控制器（和实验）无状态，可以实现可扩展性和冗余，允许在多个单独的设备上进行简单的负载平衡。</p>
<h2 id="31-生产网络上的实践">3.1 生产网络上的实践</h2>
<p>很有可能，Amy正在许多其他人使用的网络中测试她的新协议。 因此，我们希望网络具有两个额外的属性：</p>
<ol>
<li>属于 Amy 以外的用户的数据包应该使用在交换机或路由器中运行的标准且经过测试的路由协议进行路由，该协议运行在“知名品牌”供应商的交换机或路由器中。</li>
<li>Amy 应该只能为她的流量或她的网络管理员允许她控制的任何流量添加流条目。</li>
</ol>
<p>属性 1 是通过启用 OpenFlow 的交换机实现的。在 Amy 的实验中，所有不是来自 Amy 的 PC 的数据包的默认操作可能是通过正常的处理管道转发它们。 Amy 自己的数据包将直接转发到传出端口，而无需经过正常管道处理。</p>
<p>属性 2 取决于控制器。控制器应该被视为一个平台，使研究人员能够进行各种实验，而Property 2的限制可以通过适当使用权限或其他方式来限制单个研究人员控制流入口的权力来实现。这些类似权限的机制的确切性质将取决于控制器的实现方式。我们预计会出现各种各样的控制器。作为控制器具体实现的一个例子，一些作者正在开发一种称为 NOX 的控制器，作为 Ethane 工作的后续[8]。通过将 GENI 管理软件扩展到 OpenFlow 网络，可能会出现一个完全不同的控制器。</p>
<h2 id="32-更多实例">3.2 更多实例</h2>
<p>与任何实验平台一样，这组实验将超过我们可以预先想到的那些——OpenFlow 网络中的大多数实验还有待考虑。 在这里，为了说明，我们提供了一些示例，说明如何使用支持 OpenFlow 的网络来试验新的网络应用程序和架构。</p>
<ul>
<li>实验1：网络管理和接入控制。</li>
<li>实验2:VLAN。</li>
<li>实验3：移动无线VOIP客户端。</li>
<li>实验4：无IP网络。</li>
<li>实验5：处理包而不是流。</li>
</ul>
<p>在支持 OpenFlow 的网络中处理数据包有两种基本方法。 首先，也是最简单的，是强制所有流的数据包通过控制器。 为此，控制器不会将新的流条目添加到流交换机中——它只是允许交换机默认将每个数据包转发到控制器。 这具有灵活性的优势，但以性能为代价。 它可能为测试新协议的功能提供了一种有用的方法，但对于在大型网络中的部署不太可能引起人们的兴趣。</p>
<p>处理数据包的第二种方法是将它们路由到进行数据包处理的可编程交换机——例如，基于 NetFPGA 的可编程路由器。 优点是可以以用户定义的方式以线速处理数据包； 图 3 显示了如何做到这一点的示例，其中支持 OpenFlow 的交换机本质上作为一个接线板运行，以允许数据包到达 NetFPGA。 在某些情况下，NetFPGA 板（插入 Linux PC 的 PCI 板）可能会放置在支持 OpenFlow 的交换机旁边的配线柜中，或者（更有可能）放在实验室中。</p>
<p></p>
<h2 id="4--openflow联盟">4.  OpenFlow联盟</h2>
<h2 id="5-部署openflow交换机">5. 部署OpenFlow交换机</h2>
<h2 id="6-结论">6. 结论</h2>
<p>我们认为 OpenFlow 是一种务实的折衷方案，它允许研究人员以统一的方式在异构交换机和路由器上运行实验，而无需供应商公开其产品的内部工作原理，也无需研究人员编写供应商特定的控制软件。</p>
<p>如果我们在校园中成功部署 OpenFlow 网络，我们希望 OpenFlow 将逐渐在其他大学中流行起来，增加支持实验的网络数量。 我们希望出现新一代的控制软件，让研究人员能够重复使用控制器和实验，并在他人工作的基础上再接再厉。 随着时间的推移，我们希望不同大学的 OpenFlow 网络孤岛将通过隧道和覆盖网络相互连接，也许还可以通过在连接大学彼此的骨干网络中运行的新 OpenFlow 网络相互连接。</p>
]]></description>
</item>
<item>
    <title>论文笔记——The Design Philosophy of the DARPA Internet Protocols</title>
    <link>https://leeshy-tech.github.io/design_philosophy_of_darpa/</link>
    <pubDate>Tue, 28 Jun 2022 13:31:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/design_philosophy_of_darpa/</guid>
    <description><![CDATA[<h1 id="the-design-philosophy-of-the-darpa-internet-protocols">The Design Philosophy of the DARPA Internet Protocols</h1>
<p>DARPA网络协议的设计哲学</p>
<h2 id="论文概况">论文概况</h2>
<p><a href="https://dl.acm.org/doi/proceedings/10.1145/52324" target="_blank" rel="noopener noreffer">SIGCOMM &lsquo;88: Symposium proceedings on Communications architectures and protocols</a></p>
<p>August 1988 Pages 106–114</p>
<p>自翻：<a href="https://github.com/leeshy-tech/PaperTranslate/blob/main/Design_philosophy_of_DARPA.md" target="_blank" rel="noopener noreffer">https://github.com/leeshy-tech/PaperTranslate/blob/main/Design_philosophy_of_DARPA.md</a></p>
<h2 id="摘要">摘要</h2>
<p>Internet 协议套件 TCP/IP 于 15 年前（1973）首次提出。 它由国防高级研究计划局 (DARPA) 开发，并已广泛用于军事和商业系统。 虽然有描述协议如何工作的论文和规范，但有时很难从中推断出协议为何是现在的样子。 例如，Internet 协议基于无连接或数据报服务模式。 这样做的动机被大大误解了。 本文试图捕捉形成 Internet 协议的一些早期原因。</p>
<h2 id="1-引言">1 引言</h2>
<p>在过去的 15 年中，美国国防部高级研究计划局一直在开发一套用于分组交换网络的协议。 这些协议，包括 Internet 协议 (IP) 和传输控制协议 (TCP)，现在是美国国防部的互联网络标准，并在商业网络环境中广泛使用。 在这项工作中开发的想法也影响了其他协议套件，最重要的是 ISO 协议的无连接配置。</p>
<p>事实上，设计理念已经从最初的提案发展到目前的标准。 例如，数据报或无连接服务的概念在第一篇论文中并未得到特别强调，但已成为协议的定义特征。 另一个例子是将架构分层到 IP 和 TCP 层。 这似乎是设计的基础，但也不是最初提案的一部分。 互联网设计的这些变化是通过在标准制定之前发生的重复实施和测试模式而产生的。</p>
<p>互联网架构仍在不断发展。 有时新的扩展会挑战设计原则之一，但无论如何，对设计历史的理解为当前的设计扩展提供了必要的背景。 本文对互联网体系结构的最初目标进行了分类，并讨论了这些目标与协议的重要特征之间的关系。</p>
<h2 id="2-基本目标">2 基本目标</h2>
<p>DARPA 互联网架构的最高目标是开发一种有效的技术，以复用现有的互连网络。 需要有一些适当的详细说明，来明确该目标的含义。</p>
<p>最初的目标是将原始 ARPANET 与 ARPA 分组无线电网络连接在一起，以便使分组无线电网络上的用户能够访问 ARPANET 上的大型服务机器。 当时假设会有其他类型的网络可以互连，尽管局域网尚未出现。互连现有网络的一种替代方法是设计一个统一的系统，该系统结合了各种不同的传输媒体，即多媒体网络。该项目的目标是解决将多个单独管理的实体整合到一个公共设施中的问题。</p>
<p>多路复用技术：分组交换。支持的应用程序（例如远程登录）自然由分组交换范式提供服务，并且将在该项目中集成在一起的网络是分组交换网络。 因此，<strong>分组交换</strong>被接受为 Internet 体系结构的基本组成部分。</p>
<p>互联网络技术：网络将通过称为网关的 Internet 数据包交换机层互连。</p>
<p>从这些假设中得出了互联网的基本结构：一种分组交换通信设施，其中许多可区分的网络使用称为网关的分组通信处理器连接在一起，网关实现存储和转发分组算法。</p>
<h2 id="3-二层目标">3 二层目标</h2>
<p>以下列表总结了为 Internet 体系结构建立的一组更详细的目标：</p>
<ol>
<li>尽管网络或网关丢失，互联网通信仍必须继续。</li>
<li>互联网必须支持多种通信服务。</li>
<li>Internet 架构必须适应各种网络。</li>
<li>Internet 架构必须允许对其资源进行分布式管理。</li>
<li>互联网架构必须具有成本效益。</li>
<li>Internet 体系结构必须允许以较低的工作量连接主机。</li>
<li>互联网架构中使用的资源必须负责。</li>
</ol>
<p>这些目标是按重要性顺序排列的，如果顺序改变，就会产生完全不同的网络架构。 例如，由于该网络旨在在军事环境中运行，这意味着可能存在敌对环境，因此将生存能力作为首要目标，将问责制作为最后目标。</p>
<p>上面的目标列表，并不是一个“母性”列表，而是一组优先级，它们强烈地影响了 Internet 架构中的设计决策。</p>
<h2 id="4-面对失败时的生存能力">4 面对失败时的生存能力</h2>
<p>清单上最重要的目标是互联网应该继续提供通信服务，即使网络和网关出现故障。特别是，这个目标被解释为如果两个实体正在通过 Internet 进行通信，并且某些故障导致 Internet 暂时中断并重新配置以重建服务，那么通信的实体应该能够继续进行通信，而无需重新建立或重置他们对话的高级状态。更具体地说，在传输层的服务接口上，这种架构没有提供任何设施来与传输服务的客户端进行通信，即发送方和接收方之间的同步可能已经丢失。该架构中的一个假设是，除非没有可以实现任何类型通信的物理路径，否则同步永远不会丢失。</p>
<p>为了实现这一目标，描述正在进行的对话的<strong>状态信息必须受到保护</strong>。 状态信息的具体示例将是传输的数据包数量、确认的数据包数量或未完成的流控制权限的数量。 如果架构的较低层丢失了这些信息，他们将无法判断数据是否丢失，应用程序层将不得不应对同步的丢失。 该架构坚持不会发生这种中断，这意味着必须保护状态信息不丢失。</p>
<p>在某些网络架构中，此状态存储在网络的中间分组交换节点中。 在这种情况下，为了保护信息不丢失，必须对其进行复制。 由于复制的分布式特性，确保稳健复制的算法本身很难构建。它的替代方案是获取此信息并将其收集到网络的端点，即使用网络服务的实体处。将这种可靠性方法称为“命运共享”。</p>
<p>命运共享有两个重要的优势。首先，命运共享可以防止任何数量的中间故障。其次，命运共享更容易设计。</p>
<p>对于生存能力的命运共享方法有两个结果。首先，中间分组交换节点或网关不能有任何关于正在进行的连接的基本状态信息。 也就是说，它们是无状态分组交换机，被称为“数据报”网络。 其次，它对主机的信任度更高。 如果确保数据排序和确认的主机驻留算法失败，则该机器上的应用程序将无法运行。</p>
<p>尽管生存能力是列表中的首要目标，但它仍然次于顶级目标——<strong>现有网络互连</strong>。 单一的多媒体网络设计可能会产生一种更具生存能力的技术。  例如，互联网对网络报告故障的能力做出了非常微弱的假设。因此，互联网被迫使用网络级别的机制来检测网络故障，可能会出现速度较慢且不太具体的错误检测。</p>
<h2 id="5-服务类型">5 服务类型</h2>
<p>互联网架构的第二个目标是它应该在传输服务级别支持多种类型的服务。 不同类型的服务通过对速度、延迟和可靠性等方面的不同要求来区分。传统的服务类型是双向可靠的数据传输。 该服务有时称为“虚拟电路”服务，适用于远程登录或文件传输等应用程序。 它是 Internet 架构中提供的第一个服务，使用传输控制协议 (TCP) 。很早就认识到即使是此服务也有多种变体，例如远程登录和文件传输，分别对延迟和带宽敏感。 TCP 试图提供这两种类型的服务。</p>
<p>TCP 的最初概念是它可以足够通用以支持任何需要的服务类型。 然而，随着所需服务的全部范围变得清晰，似乎很难将对所有这些服务的支持构建到一个协议中。</p>
<p>TCP 范围之外的服务的第一个示例是对跨 Internet 调试器 XNET 12 的支持。 另一个不适合 TCP 的服务是数字化语音的实时传送。在实时数字语音中，主要要求不是可靠性，而是最小化和平滑传输延迟。一个重要的发现是网络中最严重的延迟来源是<strong>可靠传输机制</strong>。典型的可靠传输协议通过请求重新传输，延迟所有后续数据包的传递，直到丢失的数据包被重新传输来响应丢失的数据包。然后它按顺序传递该数据包和所有剩余的数据包。发生这种情况时的延迟可能是网络往返传递时间的许多倍，并且可能会完全破坏语音重组算法。相比之下，处理偶尔丢失的数据包非常容易。丢失的语音可以简单地用短时间的沉默代替，这在大多数情况下不会影响听者对语音的可理解性。</p>
<p>因此，在 Internet 架构开发的相当早的时候，就决定需要多种传输服务，并且架构必须至少能够实现限制可靠性、延迟或带宽的传输。</p>
<p>这个目标导致 TCP 和 IP，原本是架构中的单一协议，被分成两层。 TCP 提供了一种特定类型的服务，即可靠数据传输，而 IP 提供一个基本的构建块，可以从中构建各种类型的服务。因此可以从数据报中构建可靠的服务（通过在更高级别上进行确认和重传），或另一种牺牲可靠性换取低延迟的服务。 于是 UDP（用户数据报协议）产生了。</p>
<p>该架构不希望底层网络本身支持多种类型的服务，因为这将违反使用现有网络的目标。 相反，它希望可以使用主机和网关内的算法从基本数据报构建块构建多种类型的服务。事实证明，在没有底层网络明确支持的情况下，提供多种类型的服务比最初希望的要困难得多。 最严重的问题是，为一种特定类型的服务设计的网络不够灵活，无法支持其他服务。</p>
<h2 id="6-各种网络">6 各种网络</h2>
<p>互联网架构在实现这一目标方面非常成功；它在各种各样的网络上运行，包括长途网络、局域网、广播卫星网络，分组无线电网络，各种串行链路，以及各种其他自组织设施，包括计算机间总线和其他网络套件的更高层提供的传输服务，例如作为 IBM 的 HASP。</p>
<p>Internet 体系结构通过对网络将提供的功能做出最少的假设来实现这种灵活性。 基本假设是网络可以传输数据包或数据报。 数据包必须具有合理的大小，并且应该以合理但不完美的可靠性交付。 如果网络不仅仅是点对点链接，则网络必须具有某种合适的寻址形式。</p>
<p>有许多服务明确没有从网络中假设。这些包括可靠或有序的交付、网络级广播或多播、传输数据包的优先级排序、对多种服务的支持以及故障、速度或延迟的内部感知。如果需要这些服务，那么为了适应 Internet 中的网络，网络必须直接支持这些服务，或者网络接口软件提供增强功能以在网络端点模拟这些服务。人们认为这是一种不受欢迎的方法，因为必须为每个网络和每个网络的每个主机接口重新设计和重新实现这些服务。通过在传输过程中设计这些服务，例如通过 TCP 进行可靠交付，工程必须只完成一次，并且每个主机必须只完成一次实施。之后，新网络的接口软件的实现通常非常简单。</p>
<h2 id="7-其他目标">7 其他目标</h2>
<p>到目前为止讨论的三个目标是对架构设计产生最深远影响的目标。其余的目标，因为它们的重要性较低，可能不太有效地实现，或者没有完全设计。允许对 Internet 进行分布式管理的目标在某些方面肯定已经实现。</p>
<p>另一方面，当今互联网的一些最重要的问题与缺乏足够的分布式管理工具有关，尤其是在路由领域。 在当前运营的大型互联网中，路由决策需要受到资源使用策略的约束。 今天，这只能以非常有限的方式完成，这需要手动设置路由表。 这很容易出错，同时也不够强大。 未来几年互联网架构中最重要的变化可能是开发新一代的多部门资源管理工具。</p>
<p>很明显，在某些情况下，Internet 架构在使用昂贵的通信资源方面的成本效益不如更量身定制的架构。 Internet 数据包的报头相当长（典型的报头为 40 字节），如果发送短数据包，这种开销是显而易见的。当然，更糟糕的情况是单字符远程登录数据包，它携带 40 字节的报头和 1 字节的数据。实际上，任何协议套件都很难声称这些交换以合理的效率进行。在另一个极端，用于文件传输的大数据包（可能包含 1,000 字节数据）的报头开销仅为 4%。</p>
<p>效率低下的另一个可能原因是丢失数据包的重传。由于 Internet 不坚持在网络级别恢复丢失的数据包，因此可能需要将丢失的数据包从 Internet 的一端重新传输到另一端。这意味着重新传输的数据包可能会再次穿过几个中间网络，而网络级别的恢复不会产生这种重复流量。如果重传率足够低（例如，1%），那么增量成本是可以容忍的。</p>
<p>将主机连接到 Internet 的成本可能略高于其他架构，因为提供所需服务类型的所有机制，例如确认和重传策略，都必须在主机中而不是在网络中实现。</p>
<p>使用主机驻留机制引起的一个相关问题是该机制的不良实施可能会损害网络以及主机。这个问题是可以容忍的，因为最初的实验涉及有限数量的可以控制的主机实现。然而，随着互联网使用的增长，这个问题偶尔会以严重的方式浮出水面。在这方面，鲁棒性目标导致命运共享方法导致主机驻留算法，如果主机行为不端，则会导致鲁棒性损失。</p>
<p>最后一个目标是问责制。事实上，Cerf 和 Kahn 在第一篇论文中将记账作为协议和网关的一项重要功能进行了讨论。然而，目前，互联网架构包含很少的工具来计算数据包流。这个问题现在才被研究，因为架构的范围正在扩大到包括非军事消费者，他们非常关心理解和监控互联网内资源的使用情况。</p>
<h2 id="8-架构和实现">8 架构和实现</h2>
<p>前面的讨论清楚地表明，互联网架构的目标之一是在所提供的服务中提供广泛的灵活性。可以使用不同的传输协议来提供不同类型的服务，并且可以合并不同的网络。该体系结构非常努力地不限制互联网可以提供的服务范围，这意味着要理解 Internet 可以提供的服务，不能看架构，而要看特定主机和网关内软件的实际工程，以及特定的已纳入的网络。</p>
<p>Internet 体系结构通过设计来容忍这种多样性的实现。 然而，它给特定实现的设计者留下了大量的工程工作要做。 这种架构开发的主要挑战之一是了解如何为实现的设计者提供指导，指导将实现的工程与将产生的服务类型联系起来。 大多数已知的网络设计辅助工具似乎对回答这类问题没有帮助。例如，协议验证器有助于确认协议符合规范。然而，这些工具几乎从不处理性能问题。一个典型的实施经验是，即使在证明了逻辑正确性之后，仍会发现可能导致性能下降一个数量级的设计错误。对这个问题的探索得出的结论是，困难通常不是出现在协议本身，而是出现在协议运行的操作系统上。在这种情况下，很难在架构规范的上下文中解决该问题。但是，我们仍然强烈认为有必要给予实施者指导。我们今天继续与这个问题作斗争。</p>
<p><strong>架构</strong>和<strong>性能</strong>之间的关系是一个极具挑战性的关系。 互联网架构的设计者非常强烈地认为，只关注逻辑正确性而忽视性能问题是一个严重的错误。 但是，他们在将架构内性能约束的任何方面形式化时遇到了很大的困难。 之所以出现这些困难，一方面是因为架构的目标不是限制性能，而是允许可变性，其次（也许更根本的是），因为似乎没有有用的正式工具来描述性能。</p>
<h2 id="9-数据包">9 数据包</h2>
<p>互联网的基本架构特征是使用数据报作为跨底层网络传输的实体。正如本文所建议的，数据报在架构中很重要有几个原因。首先，它们消除了对中间交换节点内连接状态的需求，这意味着互联网可以在发生故障后重建而无需考虑状态。其次，数据报提供了一个基本的构建块，通过它可以实现各种类型的服务。与通常意味着固定类型的服务的虚拟电路相比，数据报提供了更基本的服务，端点可以适当地组合这些服务来构建所需的服务类型。第三，数据报代表了最小的网络服务假设，它允许将各种各样的网络结合到各种互联网实现中。使用数据报的决定是一个非常成功的决定，它使互联网能够非常成功地实现其最重要的目标。</p>
<p>通常与数据报相关的一个错误假设是，数据报的动机是支持更高级别的服务，该服务本质上等同于数据报。 换句话说，有时建议提供数据报，因为应用程序需要的传输服务是数据报服务。 事实上，这种情况很少见。 虽然 Internet 中的某些应用程序（例如对日期服务器或名称服务器的简单查询）使用基于不可靠数据报的访问方法，但 Internet 中的大多数服务都希望使用比简单数据报更复杂的传输模型。 一些服务希望提高可靠性，一些希望平滑和缓冲延迟，但几乎所有的服务都期望比数据报更复杂。 重要的是要了解数据报在这方面的作用是作为构建块，而不是作为服务本身。</p>
<h2 id="10-tcp">10 TCP</h2>
<p>在 TCP 的开发过程中有几个有趣和有争议的设计决策，而且 TCP 本身在成为一个相当稳定的标准之前也经历了几个主要版本。在本节中，我试图捕捉一些 TCP 部分的早期原因。 本节必然是不完整的； 完整回顾 TCP 本身的历史需要另一篇如此篇幅的论文。</p>
<p>最初的 ARPANET 主机到主机协议提供了基于字节和数据包的流量控制。 这似乎过于复杂，TCP 的设计者认为只有一种监管形式就足够了。 选择是规范字节的传递，而不是数据包。 因此，TCP 中的流量控制和确认基于字节数而不是数据包数。 实际上，在 TCP 中，数据的打包没有意义。</p>
<p>回想起来，正确的设计决策可能是，如果 TCP 要提供对各种服务的有效支持，则必须对数据包和字节进行规范，就像在原始 ARPANET 协议中所做的那样。</p>
<h2 id="11-结论">11 结论</h2>
<p>就其优先事项而言，互联网架构非常成功。 这些协议广泛用于商业和军事环境，并催生了许多类似的架构。 同时，它的成功表明，在某些情况下，设计师的优先级与实际用户的需求不匹配。 需要更加关注分管地区的会计、资源管理和运营等事项。</p>
<p>虽然数据报在解决 Internet 最重要的目标方面发挥了很好的作用，但当我们试图解决一些在优先级列表中更靠后的目标时，它就没有那么好用了。 例如，资源管理和问责制的目标已被证明在数据报的背景下难以实现。 正如上一节所讨论的，大多数数据报是从源到目的地的某些数据包序列的一部分，而不是应用程序级别的孤立单元。 但是，网关不能直接看到这个序列的存在，因为它被迫孤立地处理每个数据包。 因此，必须对每个数据包分别进行资源管理决策或计费。 将数据报模型强加于 Internet 层已经剥夺了该层可用于实现这些目标的重要信息来源。</p>
<p>这表明下一代架构可能有比数据报更好的构建块。这个构建块的一般特征是它可以识别从源到目的地的一系列数据包，而无需假设该服务具有任何特定类型的服务。我用“流”这个词来描述这个构建块。网关必须具有流状态以记住通过它们的流的性质，但状态信息对于维护与流相关联的所需服务类型并不重要。相反，该类型的服务将由端点强制执行，端点将定期发送消息以确保正确类型的服务与流相关联。这样，与流相关的状态信息可能会在崩溃中丢失，而不会永久中断正在使用的服务功能。我将这个概念称为“软状态”，它很可能使我们能够实现生存性和灵活性的主要目标，同时更好地处理资源管理和问责制问题。探索替代构建块构成了 DARPA 互联网计划的当前研究方向之一。</p>
]]></description>
</item>
<item>
    <title>SDN十篇推荐论文</title>
    <link>https://leeshy-tech.github.io/sdn_paper_recom/</link>
    <pubDate>Mon, 27 Jun 2022 17:31:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/sdn_paper_recom/</guid>
    <description><![CDATA[<h1 id="sdn十篇推荐论文">SDN十篇推荐论文</h1>
<blockquote>
<p>推荐论文来自BUPT课程“软件定义网络”</p>
</blockquote>
<h2 id="1988the-design-philosophy-of-the-darpa-internet-protocols">(1988)The Design Philosophy of the DARPA Internet Protocols</h2>
<p>DARPA互联网协议的设计哲学</p>
<p>​	Internet 协议套件 TCP/IP 于 15 年前首次提出。 它由国防高级研究计划局 (DARPA) 开发，并已广泛用于军事和商业系统。 虽然有描述协议如何工作的论文和规范，但有时很难从中推断出协议为何如此。 例如，Internet 协议基于无连接或数据报服务模式。 这样做的动机被大大误解了。 本文试图捕捉形成 Internet 协议的一些早期推理。</p>
<h2 id="2005overcoming-the-internet-impasse-through-virtualization">(2005)Overcoming the Internet Impasse through Virtualization</h2>
<p>通过虚拟化克服互联网僵化</p>
<p>当前的互联网陷入僵局，因为新架构无法部署，甚至无法进行充分评估。 本文敦促社区正视这一僵局，并提出一种可以使用虚拟化来克服它的方法。 在这个过程中，我们讨论了建筑的本质以及纯粹主义者和多元主义者之间的争论。</p>
<p>提出使用网络虚拟化技术改变互联网技术革新模式。</p>
<h2 id="2005a-clean-slate-4d-approach-to-network-control-and-management">(2005)A Clean Slate 4D Approach to Network Control and Management</h2>
<p>网络控制和管理的全新 4D 方法</p>
<p>​	当今的数据网络异常脆弱且难以管理。我们认为，这些问题的根源在于控制和管理平面的复杂性——协调网络元素的软件和协议——尤其是决策逻辑和分布式系统问题不可避免地交织在一起的方式。我们提倡对功能进行完全重构，并提出三个关键原则——网络级目标、网络范围的视图和直接控制——我们认为这些原则应该是新架构的基础。遵循这些原则，我们在架构的四个平面（决策、传播、发现和数据）之后确定了一个我们称之为“4D”的极端设计点。 4D 架构将 AS 的决策逻辑与管理网络元素之间交互的协议完全分开。 AS 级目标在决策平面中指定，并通过直接配置驱动数据平面如何转发数据包的状态来强制执行。在 4D 架构中，路由器和交换机只是按照决策平面的要求转发数据包，并收集测量数据以帮助决策平面控制网络。尽管 4D 会对当今的控制和管理平面进行重大更改，但数据包的格式不需要更改；这简化了 4D 架构的部署路径，同时仍然实现了网络控制和管理方面的重大创新。我们希望探索一个极端的设计点将有助于将研究和工业界的注意力集中在这个至关重要且具有智力挑战性的领域上。</p>
<ul>
<li>
<p>解决现有互联网问题的最大困难是分布式系统问题和决策逻辑缠绕在一起。</p>
</li>
<li>
<p>4D技术路线的要义就是分离<strong>分布式计算问题(Distributed Computing Issue)</strong></p>
<p>和<strong>组网逻辑问题(Networking Issue)。</strong></p>
</li>
</ul>
<h2 id="2007ethane-taking-control-of-the-enterprise">(2007)Ethane: Taking Control of the Enterprise</h2>
<p>早期SDN原型</p>
<p>本文介绍了 Ethane，一种适用于企业的新网络架构。 Ethane 允许管理人员定义一个单一的网络范围的细粒度策略，然后直接执行它。 Ethane 将极其简单的基于流的以太网交换机与管理流的准入和路由的集中控制器相结合。 虽然激进，但这种设计向后兼容现有的主机和交换机。 我们已经在硬件和软件中实现了 Ethane，支持有线和无线主机。 在过去的四个月里，我们运营的 Ethane 网络在斯坦福大学的网络中支持了 300 多台主机，这种部署经验对 Ethane 的设计产生了重大影响。</p>
<h2 id="2008openflow-enabling-innovation-in-campus-networks">(2008)OpenFlow: Enabling Innovation in Campus Networks</h2>
<p>​	本白皮书提出了 OpenFlow：一种供研究人员在他们每天使用的网络中运行实验协议的方法。 OpenFlow 基于以太网交换机，具有内部流表和用于添加和删除流条目的标准化接口。我们的目标是鼓励网络供应商将 OpenFlow 添加到他们的交换机产品中，以部署在大学校园骨干网和配线间中。我们认为 OpenFlow 是一种务实的折衷方案：一方面，它允许研究人员以统一的方式以线速和高端口密度在异构交换机上运行实验；另一方面，供应商不需要公开其交换机的内部工作原理。除了允许研究人员在现实世界的流量设置中评估他们的想法外，OpenFlow 还可以作为一个有用的校园组件，用于提议的大规模测试平台（如 GENI）。斯坦福大学的两座建筑物将很快使用商用以太网交换机和路由器运行 OpenFlow 网络。我们将努力鼓励在其他学校部署；我们鼓励您也考虑在您的大学网络中部署 OpenFlow。</p>
<h2 id="2013on-scalability-of-software-defined-networking">(2013)On Scalability of Software-Defined Networking</h2>
<p>论软件定义网络的可扩展性</p>
<p>在本文中，我们解构了软件定义网络中的可扩展性问题，并认为它们不是 SDN 独有的。 我们探讨了不同环境中经常出现的问题，讨论了 SDN 设计空间中的可扩展性权衡，并介绍了一些关于 SDN 可扩展性的最新研究。 此外，我们列举了超出常用性能指标的可扩展性方面被忽视但重要的机遇和挑战。</p>
<h2 id="2013improving-network-management-with-software-defined-networking">(2013)Improving Network Management with Software Defined Networking</h2>
<p>使用软件定义网络改进网络管理</p>
<p>​	网络管理具有挑战性。为了操作、维护和保护通信网络，网络运营商必须处理低级别的供应商特定配置，以实施复杂的高级网络策略。尽管之前提出了许多使网络更易于管理的建议，但由于难以改变底层基础设施，许多网络管理问题的解决方案都只是权宜之计。底层基础设施的僵化几乎没有创新或改进的可能性，因为网络设备通常是封闭的、专有的和垂直集成的。一种新的网络范式，软件定义网络（SDN），主张将数据平面和控制平面分离，使数据平面中的网络交换机成为简单的数据包转发设备，并留下一个逻辑集中的软件程序来控制整个网络的行为。 SDN 为网络管理和配置方法引入了新的可能性。在本文中，我们确定了当前最先进的网络配置和管理机制存在的问题，并介绍了改进网络管理各个方面的机制。我们关注网络管理中的三个问题：实现网络条件和状态的频繁更改，以高级语言提供网络配置支持，以及为执行网络诊断和故障排除的任务提供更好的可见性和控制。我们描述的技术使网络运营商能够以高级策略语言实施广泛的网络策略，并轻松确定性能问题的根源。除了系统本身，我们还描述了校园和家庭网络中的各种原型部署，展示了 SDN 如何改进常见的网络管理任务。</p>
<h2 id="2014a-survey-of-software-defined-networking-past-present-and-future-of-programmable-networks">(2014)A Survey of Software-Defined Networking: Past, Present, and Future of Programmable Networks</h2>
<p>软件定义网络调查：可编程网络的过去、现在和未来</p>
<p>综述了可编程网络的最新进展，重点介绍了SDN。提供了可编程网络的历史视角，从早期的想法到最近的发展。然后介绍了SDN网络的体系结构和OpenFlow标准，讨论了当前基于SDN的协议和服务的实现和测试的替代方案，考察了当前和未来的SDN应用，并探讨了基于SDN模式的有前景的研究方向。</p>
<h2 id="2014software-defined-networking-a-comprehensive-survey">(2014)Software-Defined Networking: A Comprehensive Survey</h2>
<p>在本文中，我们对 SDN 进行了全面调查。我们首先介绍 SDN 的动机，解释它的主要概念以及它与传统网络的区别、它的根源以及关于这种新颖范式的标准化活动。接下来，我们使用自下而上的分层方法展示 SDN 基础设施的关键构建块。我们对硬件基础设施、南向和北向 API、网络虚拟化层、网络操作系统（SDN 控制器）、网络编程语言和网络应用程序进行了深入分析。我们还研究了调试和故障排除等跨层问题。为了预测这种新范式的未来发展，我们讨论了 SDN 的主要正在进行的研究工作和挑战。特别是，我们解决了交换机和控制平台的设计——重点关注弹性、可扩展性、性能、安全性和可靠性等方面——以及运营商传输网络和云提供商的新机遇。最后但同样重要的是，我们分析了 SDN 作为软件定义环境的关键推动者的地位。</p>
<h2 id="2014p4-programming-protocol-independent-packet-processors">(2014)P4: Programming Protocol-Independent Packet Processors</h2>
<p>P4：编写协议无关的包处理器</p>
<p>​	P4 是一种用于编程独立于协议的包处理器的高级语言。 P4 与 OpenFlow 等 SDN 控制协议结合使用。 在目前的形式中，OpenFlow 明确指定了它所操作的协议头。 这组在几年内从 12 个字段增长到 41 个字段，增加了规范的复杂性，同时仍然不能提供添加新标头的灵活性。 在本文中，我们提出 P4 作为 OpenFlow 未来应该如何发展的草案建议。 我们有三个目标： (1) 现场可重构性：一旦部署，程序员应该能够改变交换机处理数据包的方式。 (2) 协议独立性：交换机不应与任何特定的网络协议绑定。 (3) 目标独立性：程序员应该能够独立于底层硬件的细节来描述数据包处理功能。 作为示例，我们描述了如何使用 P4 来配置交换机以添加新的分层标签。</p>
]]></description>
</item>
<item>
    <title>git使用笔记——commit格式</title>
    <link>https://leeshy-tech.github.io/git_commit_format/</link>
    <pubDate>Tue, 14 Jun 2022 14:58:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/git_commit_format/</guid>
    <description><![CDATA[<blockquote>
<p>起因是看到了三位大佬的工程https://github.com/Direktor799/rusted_os/commits/main，非常的赏心悦目，才知道commit也有固定的格式</p>
</blockquote>
<p>Commit Message格式，目前规范使用较多的是 <a href="https://github.com/angular/angular.js/blob/master/DEVELOPERS.md#-git-commit-guidelines" target="_blank" rel="noopener noreffer">Angular 团队的规范</a>, 继而衍生了 <a href="https://www.conventionalcommits.org/en/v1.0.0/" target="_blank" rel="noopener noreffer">Conventional Commits specification</a>. 很多工具也是基于此规范, 它的 message 格式如下:</p>
<p>Commit格式包含三个部分，Header、Body、Footer</p>
<pre tabindex="0"><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;
&lt;BLANK LINE&gt;
&lt;body&gt;
&lt;BLANK LINE&gt;
&lt;footer&gt;
</code></pre><ul>
<li>首行header：必填，描述修改类型和内容
<ul>
<li>scope：commit影响的范围</li>
<li>subject：commit的概述</li>
</ul>
</li>
<li>body：commit具体修改的内容</li>
<li>footer：备注，通常是 BREAKING CHANGE 或修复的 bug 的链接.</li>
</ul>
<h3 id="header">Header</h3>
<p>Header只有一行，包括三个字段<code>type</code>（必填）<code>scope</code>（可选）<code>subject</code>（必填）</p>
<h4 id="type">type</h4>
<p>说明commit的类别</p>
<ul>
<li>feat：新增功能</li>
<li>fix：bug 修复</li>
<li>docs：文档更新</li>
<li>style：不影响程序逻辑的代码修改(修改空白字符，格式缩进，补全缺失的分号等，没有改变代码逻辑)</li>
<li>refactor：重构代码(既没有新增功能，也没有修复 bug)</li>
<li>perf：性能, 体验优化</li>
<li>test：新增测试用例或是更新现有测试</li>
<li>build：主要目的是修改项目构建系统(例如 glup，webpack，rollup 的配置等)的提交</li>
<li>ci：主要目的是修改项目继续集成流程(例如 Travis，Jenkins，GitLab CI，Circle等)的提交</li>
<li>chore：不属于以上类型的其他类，比如构建流程, 依赖管理</li>
<li>revert：回滚某个更早之前的提交</li>
</ul>
<h4 id="scope">scope</h4>
<p>说明commit影响的范围，比如文件或者逻辑层。</p>
<h4 id="subject">subject</h4>
<p>commit简述</p>
<ul>
<li>以动词开头，使用第一人称现在时，比如<code>change</code>，而不是<code>changed</code>或<code>changes</code></li>
<li>第一个字母小写</li>
<li>结尾不加句号（<code>.</code>）</li>
</ul>
<h3 id="body">Body</h3>
<p>commit详细描述</p>
<h3 id="footer">Footer</h3>
<p>只用于两种情况</p>
<ol>
<li>不兼容变动</li>
<li>关闭Issue</li>
</ol>
]]></description>
</item>
<item>
    <title>论文笔记——Oracle-MNIST：a Realistic Image Dataset for Benchmarking Machine Learning Algorithms</title>
    <link>https://leeshy-tech.github.io/oracle-mnist/</link>
    <pubDate>Sun, 12 Jun 2022 14:13:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/oracle-mnist/</guid>
    <description><![CDATA[<h2 id="摘要">摘要</h2>
<p>​	我们引入了Oracle-MNIST数据集，包括10个类别的30222个古代字符的28×28灰度图像，用于基准模式分类，特别是图像噪声和失真方面的挑战。训练集共有27222张图像，测试集每个类有300张图像。Oracle-MNIST与原始MNIST数据集共享相同的数据格式，允许与所有现有的分类器和系统直接兼容，但它构成了比MNIST更具挑战性的分类任务。由于三千年的埋藏和老化，古文字的形象受到了极其严重和独特的噪音影响，以及古文字的书写风格的巨大变化，这些都使其具有机器学习研究的现实感。该数据集可以在https://github.com/wm-bupt/oracle-mnist上免费获得。</p>
<h2 id="1-引言">1 引言</h2>
<p>​	在过去的几年里，由于专门的数据集作为实验测试平台和当前进展的公共基准的发布，机器学习(ML)取得了快速的进展，从而集中了研究社区的努力。计算机视觉中最广为人知的数据集是MNIST数据集，该数据集于1998年由LeCun等人(1998)首次引入。MNIST是一个10类数字分类数据集，由60,000张用于训练的灰度图像和10,000张用于测试的灰度图像组成。整个数据集相对较小，可以自由访问和使用，并以完全直接的方式进行编码和存储，这几乎肯定有助于它的广泛使用。</p>
<p>​	然而，随着改进学习算法的发现，MNIST的性能已经饱和。例如，卷积神经网络(CNNs) (Krizhevsky等人，2012;He et al.， 2016)可以轻松达到99%以上的准确率。这部分归因于基准测试没有捕获许多真实场景的需求。为了避免饱和性能并为改进的ML算法提供挑战，构建了一些改进的MNIST数据集，例如EMNIST (Cohen等人，2017)和fashionn -MNIST (Xiao等人，2017)。EMNIST通过引入大写和小写字符扩展了类的数量，但额外的类需要改变MNIST使用的深度神经网络的框架。fashion - mnist包含10级时尚产品的7万张灰度图像。这些产品图片来源于Zalando的网站e1，由专业摄影师拍摄，清晰规范。然而，它未能在现实世界中尽可能广泛地捕捉各种变化。</p>
<p>​	本文的目的是提供一个真实且具有挑战性的数据集Oracle-MNIST，以方便ML算法对真实的古代字符图像进行简单快速的评估。oracle - mnist包含属于10个类别的oracle字符的30222个图像。</p>
<p></p>
<ol>
<li>
<p>真实世界的挑战。</p>
<p>与手写数字不同，甲骨文字符是从真实的甲骨文表面扫描而来。因此，Oracle-MNIST由于数千年的埋藏和老化而产生了极其严重和独特的噪音，并且在每个类别中都包含着各种各样的写作风格，这都使得ML研究更加现实和困难。</p>
</li>
<li>
<p>易用性。</p>
<p>与原来的MNIST相同，图像在Oracle-MNIST有28×28灰度像素。它可以立即兼容任何能够与MNIST数据集工作的ML包，因为它共享相同的数据格式。事实上，使用这个数据集需要做的唯一更改就是更改获取MNIST数据集的URL。</p>
</li>
</ol>
<h2 id="2-oracle-mnist-数据集">2 Oracle-MNIST 数据集</h2>
<h3 id="21甲骨文字符发现">2.1甲骨文字符发现</h3>
<p>​	古代史依赖于对古文字的研究。甲骨文是中国最古老的象形文字(Flad et al.， 2008;Keightley, 1997)，近三千年的历史，为现代文明做出了巨大的贡献，使中华文化得以代代相传，成为唯一延续至今的文明。如图1所示，甲骨文被镌刻在龟甲和兽骨上，记录了商朝(公元前1600-1046年)的生活和历史，包括占卜、征战、狩猎、医疗和生育等。1899年，清朝(1644-1911)，一位名叫王希荣的商人首次发现了它们。20世纪初，中国的研究人员在商朝都城河南安阳的小屯村发掘了大量的甲骨文。此后，甲骨文文字的研究备受关注。它对于中国的词源学和书法，以及学习中国古代乃至世界的文化和历史都具有重要的意义。</p>
<p></p>
<p></p>
<p></p>
<p>​	甲骨文字符大多采用扫描图像存储，扫描图像是将一张纸盖在主体上，然后用卷墨拓印，再现甲骨文表面，如图2(a)所示。识别这些甲骨文字符对专家和机器来说都很困难。到目前为止，已经发现了近4500个不同的甲骨文字符，但只有大约2200个字符被成功破译。原因如下。(1)磨损和噪声。几个世纪以来，许多甲骨铭文遭到破坏，它们的文字现在已经残缺不全。铭文的老化过程也使其不易辨认，因此扫描的文字破损，并含有严重的噪音。(2)大方差。不同的写作风格导致了类内的高度差异。如图2(b)所示，属于同一类别的字符在笔画甚至拓扑结构上都存在较大差异。不同类别的一些字符彼此相似，这给识别带来了很大的困难。例如，图2(c)和图2(d)所示的“木”和“牛”两个类别的字符仅在一些小细节上有所不同。</p>
<h3 id="22-数据集的细节">2.2 数据集的细节</h3>
<p>​	Oracle-MNIST是基于<em>殷奇文苑网站</em>的集合。这些甲骨文字是从真实的甲骨文表面扫描而来的，因此会出现破碎和噪音严重的现象。每个扫描图像的中心都有一个字符。大多数原始图像都有灰色或黑色背景，分辨率也各不相同。</p>
<p>​	我们选择了10个类的30222个常用字符构建Oracle-MNIST。然后将原始图像送入下面的转换管道，如图3所示。我们还试图通过一些图像增强技术，如灰度拉伸和直方图均衡化来处理图像。虽然成功地提高了图像的视觉质量，但识别性能略有下降。因此，Oracle-MNIST并没有采用图像增强技术。我们还提供原始图像，并将数据处理工作留给算法开发人员。</p>
<ol>
<li>将图像转换为8位灰度像素。</li>
<li>如果前景比背景暗，则取消图像的强度。</li>
<li>使用双三次插值算法将图像的最长边缘调整为28。</li>
<li>将最短的边延长到28，并将图像放到画布的中心。</li>
</ol>
<p>​	我们利用字符的含义作为它们的类标签。这些标签是由考古学或古生物学专家手工标注的。表2给出了Oracle-MNIST中所有类标签的总结，并给出了每个类的示例。</p>
<p>​	最后，我们将数据集分为训练集和测试集，并确保它们是不相交的。训练集由随机选取的27222张图像组成，测试集每类包含300张图像。图像和标签以与MNIST数据集相同的文件格式存储，MNIST数据集是为存储向量和多维矩阵而设计的。表1列出了结果文件。</p>
<p></p>
<h2 id="3-实验">3 实验</h2>
<p>​	我们在Oracle-MNIST上评估了一些不同参数的算法，结果如表3所示。对于每种算法，通过三次重复实验报告了平均分类精度。MNIST和Fashion-MNIST数据集上的基准也包括在并排比较中。</p>
<p>​	从结果中，我们有以下观察结果。首先，经典(浅层)ML算法在MNIST数据集上可以轻松实现97%，这证明了MNIST算法太容易评估。我们的Oracle-MNIST数据集提供了10类古代字符的图像，并进一步捕捉了现实世界中尽可能广泛的变化，这比MNIST数字数据和Fashion-MNIST数据提出了更具有挑战性的分类任务。我们可以看到，所有经典的(浅)ML算法在MNIST上表现最好，其次是fashionmnist，在oracle MNIST上表现最差。例如，随机森林分类器的准确率分别为97.1%、87.1%和64.9%。这是因为上文2.1节所述的类内方差和类间相似度较高，会给分类带来很大的困难。此外，由于模糊、噪声和遮挡等原因，扫描到的甲骨文图像会严重退化，甚至完全失去识别字形信息。</p>
<p>​	其次，CNN优于Oracle-MNIST上所有的经典(浅)ML算法。得益于局部接收场和空间或时间子采样，CNN可以强制提取局部特征，降低输出对位移和失真的敏感性(LeCun et al.， 1995)。因此，现实世界的挑战，如不同的写作风格，噪音和闭塞，可以在一定程度上解决。然而，Oracle-MNIST上的性能还没有饱和。本文使用的CNN在Oracle-MNIST上的错误率为6.2%，还有改进的空间。尽管CNN具有强大的表示能力，但是识别这些古文字的问题还有待完全解决。</p>
<p></p>
<p></p>
<p></p>
<p></p>
<h2 id="4-结论">4 结论</h2>
<p>​	在本文中，我们提出了一个现实的和具有挑战性的基准数据集，即Oracle-MNIST。它包含10类30222个古文字的28×28灰度图像，用于对计算机视觉中的图像噪声和失真的鲁棒性进行基准测试。Oracle-MNIST被转换成一种与构建来处理MNIST数据集的分类器直接兼容的格式。由于数千年的埋藏和老化，这些古老的文字噪音大，书写风格各异，给识别带来了很大的困难。基准测试结果表明，古文字分类任务确实更具挑战性。</p>
]]></description>
</item>
<item>
    <title>论文笔记——AMM: Attentive Multi-field Matching for News Recommendation Matching</title>
    <link>https://leeshy-tech.github.io/ammattentive_multi-field_matching/</link>
    <pubDate>Tue, 24 May 2022 17:41:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/ammattentive_multi-field_matching/</guid>
    <description><![CDATA[<h1 id="amm-attentive-multi-field-matching-for-news-recommendation">AMM: Attentive Multi-field Matching for News Recommendation</h1>
<h2 id="论文概况">论文概况</h2>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3404835.3463232" target="_blank" rel="noopener noreffer">https://dl.acm.org/doi/abs/10.1145/3404835.3463232</a></p>
<p>SIGIR &lsquo;21: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</p>
<p>July 2021 Pages 1588–1592</p>
<p><a href="https://doi.org/10.1145/3404835.3463232" target="_blank" rel="noopener noreffer">https://doi.org/10.1145/3404835.3463232</a></p>
<p>自翻：<a href="https://github.com/leeshy-tech/PaperTranslate/blob/main/AMMAttentive_Multi-field_Matching.md" target="_blank" rel="noopener noreffer">https://github.com/leeshy-tech/PaperTranslate/blob/main/AMMAttentive_Multi-field_Matching.md</a></p>
<h2 id="引言">引言</h2>
<p>​		用户兴趣与候选新闻的准确匹配是准确的个性化新闻推荐的前提。现有的方法主要是通过顺序或注意力模型聚合用户之前浏览过的新闻来学习用户的兴趣向量，然后将其与候选新闻向量进行匹配，取得了相当大的进展。例如，NPA [12] 根据候选新闻和之前点击的新闻之间的相似性来学习用户表示。 LSTUR [1] 使用 GRU 网络从点击的新闻中模拟短期和长期的用户兴趣。 NAML [11] 和 NRMS [13] 应用注意力网络从点击的新闻中学习用户表示。 FIM [9] 为每个新闻提取多级表示，并通过卷积执行细粒度匹配。然而，这些方法中的大多数将每个用户和新闻表示为单个向量，这可能会丢失文本匹配信号（例如，词级关系）。因此，我们的方法不是简单地将用户浏览的新闻建模为一个整体，而是关注每个浏览的候选新闻对之间的关系，以捕获细粒度的语义匹配表示。此外，这种对设计是在线服务友好的，匹配的表示可以离线存储，以避免重复计算。在这里，我们首先使用 BERT 来学习每个浏览候选新闻对在不同语义级别的匹配表示，然后将它们聚合到最终的用户新闻匹配信号。</p>
<p>​	此外，上述方法基于单视图新闻信息[1,9,13]或多视图信息[11]学习新闻之间的语义相关性，它们仅利用字段内语义相关性（例如，标题-标题，正文-正文）。 但有时，跨领域信息（例如标题-摘要、标题-正文）可能有利于新闻匹配。 比如新闻𝑎的标题信息丰富，而新闻𝑏的标题很吸引人，新闻𝑎的标题和新闻𝑏的正文匹配可能更好。 因此，与每条新闻相关的多个字段可能包含互补信息，这些信息促使我们学习多字段（字段内和跨字段）匹配表示。</p>
<p>​	在本文中，我们提出了一种注意力多字段匹配（AMM）框架，该框架捕获每个浏览候选新闻对的多字段语义匹配表示，然后将这些表示聚合为最终的用户新闻匹配信号，用于新闻推荐。 这项工作的主要贡献总结如下：</p>
<ul>
<li>我们提出了一种新的方法，专注于分离的浏览候选新闻对的匹配，以捕获文本语义匹配信号，这对在线服务很友好。</li>
<li>我们设计了 AMM 框架，以在领域内和跨领域的方式中提取多领域匹配表示，以深入探索用户的兴趣。</li>
<li>我们对两个公共基准数据集进行了实验，以证明我们方法的有效性。</li>
</ul>
<h2 id="我们的方法">我们的方法</h2>
<p>图 1 显示了 AMM 的整体架构。 首先，我们为每个浏览的候选新闻构建多字段对输入。 然后，匹配编码器用于提取每对输入的匹配表示。 最后，我们将所有对的匹配表示聚合到用户新闻信号以估计点击概率。</p>
<p></p>
<h3 id="21-多头部匹配">2.1 多头部匹配</h3>
<p>​	不同的新闻字段通常可以相互补充。 为了更好地编码浏览-候选匹配，我们利用字段内和跨字段匹配作为多字段信息来增强匹配表示。</p>
<p>​	给定用户浏览的新闻$\left[N_{1}, N_{2}, \ldots, N_{i}\right]$和候选新闻$N_x$，对于每个浏览-候选对$\left(N_{i}, N_{c}\right)$，我们建立多头部对输入$\left[N_{i}^{m}, N_{c}^{n}\right]$，其中$m \in{t, a, b},n \in{t, a, b}$，t、a、b分别是新闻的标题、摘要、主体。我们将新闻标题$N^t$表示为词向量$\left[w_{1}^{t}, w_{2}^{t}, \ldots, w_{\left|N^{t}\right|}^{t}\right]$，新闻摘要$N^a$表示为$\left[w_{1}^{a}, w_{2}^{a}, \ldots, w_{|N a|}^{a}\right]$，新闻主体$N^b$表示为$\left[w_{1}^{b}, w_{2}^{b}, \ldots, w_{\left|N^{\prime}\right|}^{b}\right]$，其中$\left|N^{t}\right|\left|N^{a}\right|$和$\left|N^{b}\right|$分别表示标题、摘要、主体的长度。</p>
<p>​	在这项研究中，如图 1 所示，不仅像$\left[N_{i}^{t}, N_{c}^{t}\right]$（标题和标题）这样的字段内对输入，而且像$\left[N_{i}^{t}, N_{c}^{b}\right]$（标题和正文）这样的跨字段对输入都被获得 ，这些输入对中的每一个都被馈送到匹配编码器以获得其匹配表示。 我们最终将这些表示串接为浏览候选新闻对的多字段匹配表示。</p>
<h3 id="22-匹配编码器">2.2 匹配编码器</h3>
<p>该模块用于学习每个浏览过的新闻和候选新闻之间的语义匹配。 我们将来自多字段匹配的浏览-候选多字段对作为输入，然后将其输入到来自 Transformers (BERT) [4] 的双向编码器表示中，以进行匹配表示学习。</p>
<ul>
<li>
<p>多头部自注意层</p>
<p>该子层旨在捕获句子的上下文感知语义匹配。 使用多头，来自不同位置的不同语义子空间的信息是可联合学习的，这对于捕获不同标记之间的匹配信号非常有帮助。</p>
</li>
<li>
<p>位置智慧型前馈网络</p>
<p>这个子层的目的是赋予模型非线性和不同维度之间的相互作用，这是一个完全连接的前馈网络(FFN)，它由两个线性变换组成，中间有一个ReLU激活。</p>
</li>
</ul>
<p>另外，对每个子层进行残差连接和层归一化处理。最后，我们可以通过该匹配编码器得到每个浏览-候选新闻的多字段对的匹配表示。</p>
<h3 id="23-匹配聚合器">2.3 匹配聚合器</h3>
<p>​	匹配聚合器用于聚合每个浏览新闻和候选新闻的匹配表示，以获得最终的用户新闻匹配信号。我们使用以下三种类型的聚合器获得最终的用户新闻匹配表示$\tilde{M}$：</p>
<ul>
<li>
<p>最大/平均聚合器：对的匹配嵌入直接取最大或平均作为用户-新闻匹配嵌入。
$$
\tilde{M}=\text { Aggregate }(M)=\max / \operatorname{mean}(M)\tag 5
$$</p>
</li>
<li>
<p>注意力聚合器：使用门限注意网络 [2] 来学习 𝑀 的组合权重，它应用具有$W_h$和$b_h$的全连接神经网络，使用 tanh 作为第一层激活函数，然后使用$W_o$和$b_o$构造第二个全连接神经网络来学习在等式（6）中定义的组合权重 𝑟 ，最后在等式（7）中计算词向量的线性组合。
$$
\tilde{M}=\text { Aggregate }(M)=\mathbf{r}^{\top} M\tag 6
$$</p>
<p>$$
r=\operatorname{softmax}\left(\tanh \left(\tilde{E} W_{h}+b_{h}\right) W_{o}+b_{o}\right)\tag 7
$$</p>
</li>
</ul>
<h3 id="24-点击预测">2.4 点击预测</h3>
<p>最后，我们介绍点击预测模块。 将<strong>用户-新闻匹配表示</strong>表示为$\tilde{M}$，点击概率 𝑦 通过应用全连接层计算：
$$
y=\operatorname{softmax}\left(\tilde{M} W^{o}+b^{o}\right)\tag 8
$$
其中$W^{o} \in \mathbb{R}^{d^{\prime} \times 1}$和$b^{o} \in \mathbb{R}^{1}$是可学习参数。</p>
<h2 id="3-实验">3 实验</h2>
<h3 id="31-实验设置">3.1 实验设置</h3>
<h4 id="数据集">数据集</h4>
<ul>
<li>MIND</li>
<li>Adressa</li>
</ul>
<h4 id="评价指标">评价指标</h4>
<p>​	我们使用 AUC、MRR、nDCG@𝐾，其中𝐾 = 5, 10 用于 MIND，𝐾 = 1, 3 用于 Adressa，作为我们的评估指标。 性能是所有展示日志中这些指标的平均值。</p>
<h3 id="32-性能评估">3.2 性能评估</h3>
<p>​	我们通过将 AMM 与几种基准方法进行比较来评估 AMM 的性能，</p>
<ul>
<li>LibFM [8]，分解机（FM）；</li>
<li>DeepFM[6]：一种结合了FM和神经网络的深度分解机；</li>
<li>DKN[10]，一种基于知识感知CNN的深度新闻推荐方法；</li>
<li>NPA[12]，引入注意力机制来选择重要的词和新闻；</li>
<li>NAML [11]，一种具有注意力多视图学习的神经新闻推荐方法；</li>
<li>LSTUR [1]，它使用 GRU 从点击历史中对短期和长期兴趣进行建模；</li>
<li>NRMS [13]，它使用多头自注意力来学习用户和新闻表示；</li>
<li>FIM[9]，一种用于神经新闻推荐的细粒度兴趣匹配方法；</li>
<li>AMM，我们的方法。</li>
</ul>
<p></p>
<ul>
<li>使用深度神经网络提取新闻语义表示的方法（3-8）比基于特征的方法（1-2）表现更好。这种性能改进应归功于更好的新闻表示方法。</li>
<li>在方法（3-8）中，NAML 在 MIND 中表现最好，NRMS 在 Adressa 中表现最好，这是因为 NAML 使用了不同种类的新闻信息，而 NRMS 应用了多头自注意力来进一步捕捉单词和点击新闻互动。 FIM 在所有基线中的 Adressa 中表现最好，因为它可以捕获更细粒度的兴趣匹配信号。</li>
<li>我们提出的 AMM 通过考虑分离的浏览候选新闻对和跨字段匹配来捕获多字段的更好的文本语义匹配，在所有指标方面在两个数据集上实现了最佳性能。</li>
</ul>
<h3 id="33-消融实验">3.3 消融实验</h3>
<p></p>
<ul>
<li>比较了AMM与三个单一字段(标题、摘要、正文)在MIND上的性能。
<ul>
<li>带有标题和正文的AMM的表现优于带有摘要的AMM，这表明标题和正文比摘要更有利于新闻表征。</li>
<li>此外，单个标题或正文的AMM的性能优于最佳基准，表明了分离策略引入文本语义匹配的必要性。</li>
</ul>
</li>
<li>通过实验验证了多领域匹配的有效性。
<ul>
<li>AMM多字段比AMM内字段性能更好，这可能是因为通过跨字段匹配可以融合更多的互补信息，字段内和多字段信息的集成可以提高用户新闻匹配，捕捉细粒度用户的兴趣。</li>
</ul>
</li>
<li>探讨了不同匹配聚合器的有效性。
<ul>
<li>我们可以看到带有注意力聚合器的 AMM 的性能略好于带有最大+平均池化的 AMM。 而且，最大+平均池化的表现也比 最佳基准方法好很多，验证了多字段语义匹配的有效性，这些简单的操作让在线服务更有可能。</li>
</ul>
</li>
</ul>
<h2 id="结论">结论</h2>
<p>​	在本文中，我们提出了一种新颖的注意力多领域匹配（AMM）新闻推荐框架。 我们建议以新闻分离的方式学习用户-新闻匹配表示，捕获每对浏览候选新闻的匹配表示，然后将这些表示聚合为最终匹配信号，从而获得细粒度的语义匹配信息以及它是在线服务友好的。 此外，我们的方法同时考虑了字段内和跨字段作为多字段匹配，利用了字段间的互补信息，提高了新闻对的匹配表示。 两个公共基准数据集的实验结果证明了 AMM 的最新性能。</p>
]]></description>
</item>
<item>
    <title>论文笔记——Personalized News Recommendation with Knowledge-aware Interactive Matching</title>
    <link>https://leeshy-tech.github.io/personalized_news_recommendation/</link>
    <pubDate>Mon, 23 May 2022 15:03:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/personalized_news_recommendation/</guid>
    <description><![CDATA[<h1 id="personalized-news-recommendation-with-knowledge-aware-interactive-matching">Personalized News Recommendation with Knowledge-aware Interactive Matching</h1>
<p>基于知识感知交互匹配的个性化新闻推荐</p>
<h2 id="论文概况">论文概况</h2>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3404835.3462861" target="_blank" rel="noopener noreffer">https://dl.acm.org/doi/abs/10.1145/3404835.3462861</a></p>
<p>SIGIR &lsquo;21: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</p>
<p>July 2021 Pages 61–70</p>
<p><a href="https://doi.org/10.1145/3404835.3462861" target="_blank" rel="noopener noreffer">https://doi.org/10.1145/3404835.3462861</a></p>
<p>自翻：<a href="https://github.com/leeshy-tech/PaperTranslate/blob/main/Personalized_news_recommendation_with_%20Knowledge-aware_Interactive_Matching.md" target="_blank" rel="noopener noreffer">https://github.com/leeshy-tech/PaperTranslate/blob/main/Personalized_news_recommendation.md</a></p>
<h2 id="摘要">摘要</h2>
<p>​	在本文中，我们提出了一种用于新闻推荐的知识感知交互式匹配方法。我们的方法以交互方式对候选新闻和用户兴趣进行建模，以促进它们的准确匹配。我们设计了一个知识感知新闻协同编码器，在知识图谱的帮助下捕获它们在语义和实体中的相关性，交互式地学习点击新闻和候选新闻的表示。我们还设计了一个用户新闻协同编码器来学习候选新闻感知用户兴趣表示和用户感知候选新闻表示，以实现更好的兴趣匹配。在两个真实世界数据集上的实验验证了，我们的方法可以有效地提高新闻推荐的性能。</p>
<h2 id="1-引言">1 引言</h2>
<p>​	现有方法通常根据其文本信息对候选新闻进行建模，并以独立的方式从用户的点击历史中推断出用户兴趣[21, 37]。 候选新闻文章可能包含多个方面和实体 [18、33]，并且用户可能有多个兴趣 [32]。 因此，候选新闻和用户兴趣的独立建模可能不如兴趣匹配[31]。</p>
<p>​	在本文中，我们探索更好地模拟候选新闻和用户兴趣之间的相关性，以实现准确的兴趣匹配。 我们的论文受到以下观察的启发。</p>
<p></p>
<ol>
<li>
<p>候选新闻可能涵盖不同的方面和实体，并且用户可能有多种兴趣。</p>
<p>例如，图中 候选新闻2 与篮球明星和政治家有关，含有多个实体（库里和特朗普）。示例用户对车、音乐、体育等领域感兴趣，第二个候选新闻只能匹配特定的用户兴趣即“体育”，但是用户可能只对实体“库里”感兴趣。所以如果独立建模，用候选新闻匹配用户兴趣的效果是较差的。</p>
</li>
<li>
<p>候选新闻和点击新闻的语义匹配有助于更准确地进行兴趣匹配。</p>
<p>例如，第二条点击新闻也与第一条候选新闻有语义相关性，因为它们提到了相同的事件。基于这些语义相关性，我们可以推断用户可能对第一个候选新闻感兴趣。</p>
</li>
<li>
<p>借助知识图谱，点击新闻和候选新闻中实体之间的知识匹配也有助于了解用户对候选新闻的兴趣。</p>
<p>例如，第 4 条点击新闻中的实体“史蒂夫·科尔”与第 2 条候选新闻中的实体“斯蒂芬·库里”具有内在关联，因为前者和后者分别是“NBA”勇士队的球员和教练。根据知识匹配，我们可以推断出用户可能对第二个候选新闻感兴趣。因此，在语义和知识层面利用点击新闻和候选新闻之间的相关性有利于兴趣匹配。</p>
</li>
</ol>
<p>​	在本文中，我们提出了一种用于个性化新闻推荐的知识感知交互式匹配框架（命名为KIM）。我们的方法可以交互地对候选新闻和用户兴趣进行建模，以学习候选新闻感知的用户兴趣表示和用户感知的候选新闻表示，从而更准确地匹配用户兴趣和候选新闻。在该框架中，我们提出了一种知识协同编码器，借助知识图谱从点击新闻中的实体与候选新闻中的实体之间的相关性来建模用户对候选新闻的兴趣。</p>
<p>​	更具体地说，我们</p>
<ol>
<li>
<p>首先提出了一个<strong>图协同注意网络（ graph co-attention network）</strong>：</p>
<p>它通过选择和聚合对兴趣匹配有用的邻居，从知识图谱中学习实体的表示。</p>
</li>
<li>
<p>进一步提出了使用<strong>实体协同注意力网络（ entity co-attention network）</strong>：</p>
<p>它通过捕获实体之间的相关性来交互式地学习点击新闻和候选新闻的基于知识的表示。</p>
</li>
<li>
<p>提出了一种<strong>语义协同编码器（ semantic coencoder）</strong>：</p>
<p>通过对文本之间的语义相关性进行建模，交互式地学习用户点击新闻和候选新闻的基于语义的表示。新闻的统一表示被表述为基于知识和语义的表示的聚合。</p>
</li>
<li>
<p>进一步提出了一种<strong>用户新闻联合编码器（ user-news co-encoder）</strong>：</p>
<p>用于从点击新闻和候选新闻的表示中构建候选<em>新闻感知的用户兴趣表示</em>和<em>用户感知的候选新闻表示</em>，以更好地模拟用户对候选新闻的兴趣。最后，根据候选新闻的表示与用户兴趣之间的相关性对候选新闻进行排名。</p>
</li>
</ol>
<p>我们对两个真实的数据集进行了广泛的实验，并表明我们的方法可以有效地提高新闻推荐的性能并优于其他基准方法。</p>
<h2 id="2-相关的工作">2 相关的工作</h2>
<p>​	现有方法通常通过内容对候选新闻进行建模，并根据点击新闻独立建模用户兴趣，然后根据候选新闻和用户兴趣的相关性进行匹配。 只有一部分候选新方面和用户兴趣对匹配用户兴趣和候选新闻有用。然而，这些方法独立地对候选新闻和用户兴趣进行建模，这对于进一步的兴趣匹配可能较差。与这些方法不同的是，在 KIM 方法中，我们提出了一个知识感知的交互式匹配框架，在考虑相关性的情况下对候选新闻和用户兴趣进行交互建模，可以更好地将用户兴趣与候选新闻进行匹配。</p>
<p>​	一些方法以候选感知的方式模拟用户兴趣。事实上，候选新闻可能包含多个方面和实体，其中只有一部分可能与用户兴趣相匹配。然而，这些方法在没有考虑目标用户的情况下对候选新闻进行建模，这对于进一步将用户兴趣与候选新闻进行匹配可能较差。与这些方法不同，我们的 KIM 方法在考虑目标用户的情况下对候选新闻进行建模。此外，这些方法在没有考虑相关性的情况下对点击新闻和候选新闻进行建模，这对于进一步衡量候选新闻和从点击新闻推断出的用户兴趣之间的相关性也可能不是最优的。与这些方法不同，KIM 可以交互地学习点击新闻和候选新闻的表示，以实现更好的兴趣匹配。</p>
<h2 id="3-方法论">3 方法论</h2>
<h3 id="问题表述">问题表述</h3>
<p>​	给定一个用户𝑢和一个候选新闻$n^c$，我们需要计算相关性分数𝑧来衡量用户𝑢对候选新闻内容$n^c$的兴趣。 然后根据相关性得分对不同的候选新闻进行排名并推荐给用户𝑢。 用户𝑢与他/她点击的新闻集相关联。 每个新闻 𝑛 都与其文本 𝑇 和文本中的实体 𝐸 相关联。 此外，还有一个知识图 G 用于提供实体之间的相关性。 它包含实体和实体之间的关系。 G 中的每个实体 𝑒 与其嵌入相关联，e 基于知识图进行预训练。</p>
<p></p>
<h3 id="kim-knowledge-aware-interactive-matching的框架">KIM（ Knowledge-aware Interactive Matching）的框架</h3>
<p>​	KIM 包含两个主要模块。：</p>
<ol>
<li>
<p>第一个是知识感知新闻协同编码器（knowledge-aware news co-encoder），它通过捕获语义和知识层面的相关性，交互式地学习用户<strong>点击新闻</strong>和<strong>候选新闻</strong>的<strong>知识感知表示</strong>（ knowledge-aware representations）。</p>
</li>
<li>
<p>第二个是用户新闻协同编码器（user-news co-encoder），它从上个模块生成的用户<strong>点击新闻的表征</strong>和<strong>候选新闻表征</strong>中交互学习候选新闻感知的用户兴趣表征（ candidate news-aware user interest representation）u和用户感知的候选新闻表征（ user-aware candidate news representation）。</p>
</li>
</ol>
<h3 id="知识感知新闻协同编码器knowledge-aware-news-co-encoder">知识感知新闻协同编码器（knowledge-aware news co-encoder）</h3>
<p>​	它从文本和文本中的实体中交互式地学习用户点击的新闻$n_u$和候选新闻$n_c$的表示，它包含三个子模块。</p>
<p></p>
<ol>
<li>
<p>第一个是知识协同编码器（Knowledge co-encoder）</p>
<p>对于点击新闻$n_u$和候选新闻$n_c$，它基于知识图谱从<strong>实体</strong>之间的相关性中交互式地学习基于知识的表示${k}^{u}$$和 $${k}^{c}$。</p>
<p>它包含三个组件：</p>
<ul>
<li>图注意网络（ graph attention network）</li>
<li>图协同注意网络（ graph co-attention network）</li>
<li>实体协同注意网络（ entity co-attention network）</li>
</ul>
<p></p>
</li>
<li>
<p>第二个是语义协同编码器（semantic co-encoder）</p>
<p>对于点击新闻$n_u$和候选新闻$n_c$，它交互式地学习基于语义的表示${t}^{u}$和${t}^{c}$，以根据<strong>文本</strong>之间的语义相关性来模拟用户对候选新闻的兴趣。</p>
<p></p>
</li>
<li>
<p>最后，对于点击新闻$n_u$或候选新闻$n_c$，我们投影其基于<strong>知识</strong>和<strong>语义</strong>的表示来学习统一的新闻表示${n}^{u}$或${n}^{c}$。</p>
</li>
</ol>
<h3 id="用户-新闻-协同编码器">用户-新闻 协同编码器</h3>
<p>​	它从用户点击的新闻和候选新闻的表示中学习候选新闻感知的用户兴趣表示和用户感知的候选新闻表示。</p>
<p>​	通常，用户的兴趣是多样的，只有一部分可以与候选新闻匹配[20]。因此，学习候选<strong>新闻感知的</strong>用户兴趣表示可以更好地建模用户兴趣以匹配候选新闻。</p>
<p>​	类似地，候选新闻可能涵盖多个方面，用户可能只对其中的一部分感兴趣 [33, 34]。因此，学习<strong>用户感知的</strong>候选新闻表示也有利于兴趣匹配。</p>
<p>​	因此，我们应用新闻协同注意网络来学习候选新闻感知用户表示和用户感知候选新闻表示。</p>
<h2 id="实验">实验</h2>
<h3 id="数据集">数据集</h3>
<ul>
<li>MIND2</li>
<li>Feeds</li>
</ul>
<p>此外，我们在实验中使用了 WikiData 作为知识图谱。</p>
<h3 id="性能评估">性能评估</h3>
<p>​	我们将 KIM 与几种最先进的个性化新闻推荐方法进行比较，如下所示：</p>
<ul>
<li>EBNR [21]：通过 GRU 网络从用户的点击历史中表示用户兴趣。</li>
<li>DKN [32]：将多通道 CNN 网络 [15] 应用于新闻标题中对齐的单词和实体的嵌入，以学习新闻表示。</li>
<li>DAN [47]：通过 CNN 网络从新闻标题的单词和实体中学习新闻表示，并通过细心的 LSTM 网络 [8] 学习用户兴趣表示。</li>
<li>NAML [33]：通过多个注意力集中的 CNN 网络从新闻标题、正文、类别和子类别中学习新闻表示。</li>
<li>NPA [34]：使用具有个性化注意查询的注意网络来学习新闻和用户表示。</li>
<li>LSTUR [1]：通过 GRU 网络从用户最近点击的新闻中建模短期用户兴趣，并通过用户 ID 嵌入建模长期用户兴趣。</li>
<li>NRMS [37]：通过多头自注意力网络对新闻内容和用户点击行为进行建模。</li>
<li>FIM [31]：通过CNN网络从用户点击新闻和候选新闻的文本中匹配用户和新闻。</li>
<li>KRED [18]：通过图注意力网络从新闻中的实体及其在知识图中的邻居中学习新闻的表示。</li>
</ul>
<p></p>
<p>​	我们重复了五次不同的实验，并在表 2 中列出了不同方法的平均性能和相应的标准差。</p>
<ul>
<li>
<p>KIM 明显优于其他基准方法。</p>
<p>LSTUR、NRMS和KRED这些方法独立地对候选新闻和用户兴趣进行建模，而不考虑它们的相关性。这是因为用户可能对多个领域感兴趣，并且候选新闻也可能包含多个方面和实体。因此，这些方法很难准确匹配用户兴趣和候选新闻，因为它们是在这些方法中独立建模的。</p>
</li>
<li>
<p>KIM 还优于通过考虑候选新闻来建模用户兴趣的基线方法。</p>
<p>例如 DKN、DAN。这是因为候选新闻可能涵盖多个方面，而用户可能只对其中的一部分感兴趣[33、34]。然而，这些方法在没有考虑目标用户的情况下对候选新闻进行建模，这对于进一步将候选新闻与用户兴趣匹配可能较差。</p>
</li>
</ul>
<h3 id="消融实验">消融实验</h3>
<p>​	进行了两项消融研究来评估 KIM 的有效性。首先评估不同信息（即文本和知识）对新闻内容建模的有效性。</p>
<p></p>
<ul>
<li>首先，删除语义信息（即新闻文本）会严重损害 KIM 的性能。这是因为文本通常包含有关新闻内容的丰富信息，对于新闻内容的理解至关重要 [45]。去除语义信息会使新闻表示失去很多重要信息，并且不能准确地对新闻内容进行建模。</li>
<li>其次，在新闻内容建模中去除知识图谱（即知识知识图谱中的实体及其邻居）也会使 KIM 的性能显著下降。这是因为文本信息通常不足以理解新闻内容 [18, 32]。幸运的是，知识图谱包含不同实体之间的丰富关联。此外，用户点击新闻中的实体与候选新闻之间的相关性可以提供语义信息之外的丰富信息，以了解用户对候选新闻的兴趣。因此，将实体信息纳入个性化新闻推荐有可能提高推荐的准确性。</li>
</ul>
<p>​	接下来，我们通过分别用注意力网络替换它们来评估 KIM 中几个重要的注意力网络的有效性。</p>
<ul>
<li>首先，在用户新闻协同编码器中去除<strong>新闻关注网络</strong>后，KIM 的性能变得更差。这是因为用户兴趣可能是多样的，并且只有一部分用户点击的新闻对于建模用户兴趣和候选新闻之间的相关性是有用的[32]。此外，候选新闻内容可能包含多个方面，用户可能只对其中的一部分感兴趣。因此，通过新闻共同关注网络学习候选新闻感知用户兴趣和用户感知候选新闻表示可以更好地捕捉用户对候选新闻的兴趣。</li>
<li>其次，去除<strong>语义协同注意网络</strong>也会损害 KIM 的性能。这是因为点击新闻和候选新闻之间的语义相关性可以帮助理解用户对候选新闻的兴趣。此外，一条候选新闻或一条点击新闻通常包含多个方面，其中只有一部分对兴趣匹配有用。如果它们的语义信息是独立建模的，则很难在语义级别有效地捕捉点击新闻和候选新闻的相关性。因此，通过语义共同注意网络交互式学习点击新闻和候选新闻的基于语义的表示可以更好地捕捉它们之间的相关性，以便将用户兴趣与候选新闻匹配。</li>
<li>同时去除<strong>图协同注意力网络</strong>和<strong>实体协同注意力网络</strong>会导致 KIM 的性能下降。这是因为实体级别的点击新闻和候选新闻之间的相关性对于兴趣匹配也非常有用。此外，如果该方法独立地表示来自其实体的点击新闻和候选新闻，则对于兴趣匹配也是次优的。在KIM方法中，图协同注意力网络和实体协同注意力网络都用于以交互方式捕捉点击新闻和候选新闻实体之间的相关性，可以将丰富的信息融入KIM模型进行兴趣匹配。</li>
</ul>
<h2 id="结论">结论</h2>
<p>​	在本文中，我们提出了一种用于个性化新闻推荐的知识感知交互式匹配框架（命名为 KIM）。该框架旨在对候选新闻和用户兴趣进行交互建模，以实现更准确的兴趣匹配。更具体地说，我们首先提出了一个图协同注意网络，通过选择和聚合它们的邻居的信息来基于知识图对实体进行建模，这些信息为兴趣匹配提供了丰富的信息。我们还提出使用实体协同注意网络从实体之间的相关性中交互式地对点击新闻和候选新闻进行建模。此外，我们建议使用语义共同注意网络从文本之间的语义相关性中交互式地对点击新闻和候选新闻进行建模。此外，我们提出了一种用户新闻协同编码器来学习候选新闻感知用户表示和用户感知候选新闻表示，以更好地捕捉用户兴趣和候选新闻之间的相关性。我们对两个真实世界的数据集进行了广泛的实验。实验结果表明，我们的 KIM 方法显著优于其他基准方法。</p>
]]></description>
</item>
<item>
    <title>论文笔记——RMBERT: News Recommendation via Recurrent Reasoning Memory Network over BERT</title>
    <link>https://leeshy-tech.github.io/rmbert/</link>
    <pubDate>Mon, 23 May 2022 15:03:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/rmbert/</guid>
    <description><![CDATA[<h1 id="rmbert-news-recommendation-via-recurrent-reasoning-memory-network-over-bert">RMBERT: News Recommendation via Recurrent Reasoning Memory Network over BERT</h1>
<h2 id="论文概况">论文概况</h2>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3404835.3463234" target="_blank" rel="noopener noreffer">https://dl.acm.org/doi/abs/10.1145/3404835.3463234</a></p>
<p>SIGIR &lsquo;21: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</p>
<p>July 2021 Pages 1773–1777</p>
<p><a href="https://doi.org/10.1145/3404835.3463234" target="_blank" rel="noopener noreffer">https://doi.org/10.1145/3404835.3463234</a></p>
<h2 id="摘要">摘要</h2>
<p>​	现有的方法大多是根据新闻内容将每个用户和新闻分别编码为向量，然后对两个向量进行匹配。但是，用户对每个新闻或新闻的每个主题的兴趣可能是不同的。动态地学习用户和新闻向量，并对他们的互动进行建模是必要的。</p>
<p>​	在本研究中，我们提出了基于BERT的循环推理记忆网络(RMBERT)用于新闻推荐。与其他方法相比，我们的方法可以利用BERT的内容建模能力。此外，循环推理记忆网络执行一系列基于注意力的推理步骤，可以动态学习用户和新闻向量，并对每一步的交互进行建模。因此，我们的方法可以更好地模拟用户的兴趣。我们在真实世界的新闻推荐数据集上进行了广泛的实验，结果表明，我们的方法显著优于现有的最先进的方法。</p>
<h2 id="1-引言">1 引言</h2>
<p>​	最近，一些方法探索使用神经网络以端到端方式学习新闻和用户表示，并在训练过程中优化这些表示。DKN [13]， NPA [15]， LSTUR[1]提出使用CNN学习新闻表示，然后将候选新闻与用户点击的新闻进行匹配。DKN将知识图表示引入新闻推荐。NPA通过嵌入用户ID来关注重要词汇和新闻，增强了新闻和用户表示。LSTUR结合了长期和短期用户表示，以更精确地对用户进行建模。NRMS[16]引入多头自我注意学习新闻表示。FIM[12]通过叠加扩张卷积提取每个新闻的多层表示。</p>
<p>​	在新闻推荐场景中有两个常见的观察结果。首先，不同的用户可能对候选人新闻的不同部分感兴趣。第二，用户的兴趣通常是多样化的，用户历史中不同的新闻代表了该用户的不同兴趣。以前的工作 [9, 13, 16] 使用一个固定的嵌入向量来表示用户和新闻，这可能会限制模型的表达能力。作为一个解决方案，我们需要动态地确定关于候选新闻的用户向量。记忆网络能够捕获两个对象之间的高阶复杂关系，在问题回答[4,7]、情感分析[11]、机器理解[10]等领域都取得了很大的进展。受其成功的激励，我们设计了一个循环结构的迭代推理过程，多个推理记忆单元(RMC)级联执行结构化推理操作，一步一步确定匹配分数。</p>
<p>​	我们的方法的体系结构如图1所示。</p>
<ul>
<li>新闻编码器模块通过处理每个新闻的标题并生成新闻嵌入来提取候选新闻和一些用户点击的新闻。</li>
<li>在此之后，循环推理记忆网络中包含一些以新闻嵌入为输入的rmc，它们协同工作，逐级执行推理过程。在每一步中，RMC通过查询单元和存储单元进行推理操作。查询单元使用注意机制来选择用户可能感兴趣的候选新闻嵌入的某些方面来更新查询状态。所述存储单元根据查询状态，从用户点击的新闻嵌入中动态检索用户的兴趣。经过几个推理步骤后，RMBERT可以从多个方面捕获用户对候选新闻的偏好。</li>
<li>最后，我们根据最后的存储状态来推荐新闻，该状态包含了用户和候选新闻之间的交互信息。</li>
</ul>
<p></p>
<p>​	这项工作的主要贡献总结如下。</p>
<ol>
<li>我们使用BERT对候选新闻和用户点击新闻进行独立编码。我们的方法可以利用BERT的表达能力，同时获得离线预计算新闻嵌入的能力。</li>
<li>我们提出了一种循环结构来逐步执行基于注意力的推理操作。 在每个步骤中，RMC 可以推断候选新闻的某些部分与用户兴趣之间的匹配分数。 RMC可以在每一步动态确定新闻和用户向量，并在多方面探索它们的匹配。</li>
<li>从MSN新闻收集的真实数据集上进行的大量实验证实，我们的方法比现有的最先进的方法具有更好的性能。</li>
</ol>
<h2 id="2-提出的方法">2 提出的方法</h2>
<h3 id="21-新闻编码器">2.1 新闻编码器</h3>
<h3 id="22-推理存储单元">2.2 推理存储单元</h3>
]]></description>
</item>
<item>
    <title>网络实验——在linux平台安装OLSR协议</title>
    <link>https://leeshy-tech.github.io/network_olsr_with_mininet-wifi/</link>
    <pubDate>Sun, 27 Mar 2022 22:26:06 &#43;0800</pubDate><author>saili@bupt.edu.cn (Leeshy)</author><guid>https://leeshy-tech.github.io/network_olsr_with_mininet-wifi/</guid>
    <description><![CDATA[<h1 id="在linux平台安装olsr协议">在linux平台安装OLSR协议</h1>
<h2 id="前言">前言</h2>
<p>因为要做一个OLSR和SDN自定义控制面的对比实验，所以要利用mininet-wifi平台自定义拓扑跑一下OLSR协议。</p>
<p>平台：ubuntu20.04</p>
<h2 id="安装">安装</h2>
<ul>
<li>
<p>官网：<a href="www.olsr.org/" rel="">www.olsr.org/</a></p>
</li>
<li>
<p>github：<a href="https://github.com/OLSR/olsrd" target="_blank" rel="noopener noreffer">https://github.com/OLSR/olsrd</a></p>
</li>
</ul>
<h3 id="通过mininet-wifi安装">通过mininet-wifi安装</h3>
<ul>
<li>进入mininet-wifi目录<code>sudo ./install.sh -o</code></li>
</ul>
<h3 id="从git安装没有亲自试来自网络">从git安装(没有亲自试，来自网络)</h3>
<ul>
<li>
<p>安装语法分析器：<code>sudo apt install bison flex</code></p>
</li>
<li>
<p>下载源码：<code>git clone https://github.com/OLSR/olsrd</code></p>
</li>
<li>
<p>编译：<code>cd olsrd;make</code></p>
</li>
<li>
<p>安装：<code>sudo make install</code></p>
</li>
</ul>
<h2 id="mininet-wifi拓扑构建">mininet-wifi拓扑构建</h2>
<blockquote>
<p>构造一个网络拓扑来测试OLSR协议。</p>
</blockquote>
<p>拓扑文件（参考example/adhoc.py）：</p>
<p><a href="https://github.com/leeshy-tech/mininet-wifi/blob/master/examples/OLSR/olsr_test.py" target="_blank" rel="noopener noreffer">https://github.com/leeshy-tech/mininet-wifi/blob/master/examples/OLSR/olsr_test.py</a></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="ch">#!/usr/bin/python</span>

<span class="s2">&#34;&#34;&#34;
</span><span class="s2">This example use four motionless station to test the OLSR protocol in adhoc network.
</span><span class="s2">It&#39;s almost the same as example/adhoc.py.
</span><span class="s2">use &#34;sudo python olsr_test.py olsrd&#34; in terminal to run it.
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">from</span> <span class="nn">mininet.log</span> <span class="kn">import</span> <span class="n">setLogLevel</span><span class="p">,</span> <span class="n">info</span>
<span class="kn">from</span> <span class="nn">mn_wifi.link</span> <span class="kn">import</span> <span class="n">wmediumd</span><span class="p">,</span> <span class="n">adhoc</span>
<span class="kn">from</span> <span class="nn">mn_wifi.manetRoutingProtocols</span> <span class="kn">import</span> <span class="n">olsrd</span>
<span class="kn">from</span> <span class="nn">mn_wifi.cli</span> <span class="kn">import</span> <span class="n">CLI</span>
<span class="kn">from</span> <span class="nn">mn_wifi.net</span> <span class="kn">import</span> <span class="n">Mininet_wifi</span>
<span class="kn">from</span> <span class="nn">mn_wifi.wmediumdConnector</span> <span class="kn">import</span> <span class="n">interference</span>


<span class="k">def</span> <span class="nf">topology</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="s2">&#34;Create a network.&#34;</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Mininet_wifi</span><span class="p">(</span><span class="n">link</span><span class="o">=</span><span class="n">wmediumd</span><span class="p">,</span> <span class="n">wmediumd_mode</span><span class="o">=</span><span class="n">interference</span><span class="p">)</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Creating nodes</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">if</span> <span class="s1">&#39;-a&#39;</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;range&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>

    <span class="n">sta1</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">addStation</span><span class="p">(</span><span class="s1">&#39;sta1&#39;</span><span class="p">,</span> <span class="n">ip6</span><span class="o">=</span><span class="s1">&#39;fe80::1&#39;</span><span class="p">,</span><span class="n">position</span><span class="o">=</span><span class="s1">&#39;25,50,0&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">sta2</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">addStation</span><span class="p">(</span><span class="s1">&#39;sta2&#39;</span><span class="p">,</span> <span class="n">ip6</span><span class="o">=</span><span class="s1">&#39;fe80::2&#39;</span><span class="p">,</span><span class="n">position</span><span class="o">=</span><span class="s1">&#39;75,10,0&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">sta3</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">addStation</span><span class="p">(</span><span class="s1">&#39;sta3&#39;</span><span class="p">,</span> <span class="n">ip6</span><span class="o">=</span><span class="s1">&#39;fe80::3&#39;</span><span class="p">,</span><span class="n">position</span><span class="o">=</span><span class="s1">&#39;75,90,0&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">sta4</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">addStation</span><span class="p">(</span><span class="s1">&#39;sta4&#39;</span><span class="p">,</span> <span class="n">ip6</span><span class="o">=</span><span class="s1">&#39;fe80::4&#39;</span><span class="p">,</span><span class="n">position</span><span class="o">=</span><span class="s1">&#39;125,50,0&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">net</span><span class="o">.</span><span class="n">setPropagationModel</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&#34;logDistance&#34;</span><span class="p">,</span> <span class="n">exp</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Configuring wifi nodes</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">configureWifiNodes</span><span class="p">()</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Creating links</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="c1"># MANET routing protocols supported by proto:</span>
    <span class="c1"># babel, batman_adv, batmand and olsr</span>
    <span class="c1"># WARNING: we may need to stop Network Manager if you want</span>
    <span class="c1"># to work with babel</span>
    <span class="n">protocols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;babel&#39;</span><span class="p">,</span> <span class="s1">&#39;batman_adv&#39;</span><span class="p">,</span> <span class="s1">&#39;batmand&#39;</span><span class="p">,</span> <span class="s1">&#39;olsrd&#39;</span><span class="p">,</span> <span class="s1">&#39;olsrd2&#39;</span><span class="p">]</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">proto</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">proto</span> <span class="ow">in</span> <span class="n">protocols</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;proto&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">proto</span>

    <span class="n">net</span><span class="o">.</span><span class="n">addLink</span><span class="p">(</span><span class="n">sta1</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">adhoc</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s1">&#39;sta1-wlan0&#39;</span><span class="p">,</span>
                <span class="n">ssid</span><span class="o">=</span><span class="s1">&#39;adhocNet&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">ht_cap</span><span class="o">=</span><span class="s1">&#39;HT40+&#39;</span><span class="p">,</span>  <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">addLink</span><span class="p">(</span><span class="n">sta2</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">adhoc</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s1">&#39;sta2-wlan0&#39;</span><span class="p">,</span>
                <span class="n">ssid</span><span class="o">=</span><span class="s1">&#39;adhocNet&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">ht_cap</span><span class="o">=</span><span class="s1">&#39;HT40+&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">addLink</span><span class="p">(</span><span class="n">sta3</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">adhoc</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s1">&#39;sta3-wlan0&#39;</span><span class="p">,</span>
                <span class="n">ssid</span><span class="o">=</span><span class="s1">&#39;adhocNet&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">ht_cap</span><span class="o">=</span><span class="s1">&#39;HT40+&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">addLink</span><span class="p">(</span><span class="n">sta4</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">adhoc</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s1">&#39;sta4-wlan0&#39;</span><span class="p">,</span>
                <span class="n">ssid</span><span class="o">=</span><span class="s1">&#39;adhocNet&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">ht_cap</span><span class="o">=</span><span class="s1">&#39;HT40+&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">net</span><span class="o">.</span><span class="n">plotGraph</span><span class="p">(</span><span class="n">max_x</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">max_y</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Starting network</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">*** Addressing...</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">&#39;proto&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">sta1</span><span class="o">.</span><span class="n">setIP6</span><span class="p">(</span><span class="s1">&#39;2001::1/64&#39;</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s2">&#34;sta1-wlan0&#34;</span><span class="p">)</span>
        <span class="n">sta2</span><span class="o">.</span><span class="n">setIP6</span><span class="p">(</span><span class="s1">&#39;2001::2/64&#39;</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s2">&#34;sta2-wlan0&#34;</span><span class="p">)</span>
        <span class="n">sta3</span><span class="o">.</span><span class="n">setIP6</span><span class="p">(</span><span class="s1">&#39;2001::3/64&#39;</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s2">&#34;sta3-wlan0&#34;</span><span class="p">)</span>
        <span class="n">sta4</span><span class="o">.</span><span class="n">setIP6</span><span class="p">(</span><span class="s1">&#39;2001::4/64&#39;</span><span class="p">,</span> <span class="n">intf</span><span class="o">=</span><span class="s2">&#34;sta4-wlan0&#34;</span><span class="p">)</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Running CLI</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">CLI</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

    <span class="n">info</span><span class="p">(</span><span class="s2">&#34;*** Stopping network</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">setLogLevel</span><span class="p">(</span><span class="s1">&#39;info&#39;</span><span class="p">)</span>
    <span class="n">topology</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>
</code></pre></div><p>可视化：</p>
<p></p>
<p>解读：</p>
<p>从图中可以看出，sta1只能与sta2和sta3进行单跳通信，如果要与sta4通信，就需要sta2或者sta3进行中继。如果没有OLSR协议，节点在收到目的IP不是本节点的包之后就会丢掉，无法完成中继。OLSR协议会在网络中的节点维护整个网络拓扑，就能完成中继。</p>
<h2 id="实验测试">实验测试</h2>
<h3 id="关闭networkmanager">关闭NetworkManager</h3>
<p><code>sudo systemctl stop NetworkManager</code></p>
<p>NetworkManager是linux的自动网络配置工具，我们希望自己配置网络，所以要把它关掉。</p>
<p>查看节点的网络状态<code>ip addr</code>，没有图中的<code>NO-CARRIER</code>说明NetworkManager已经被关闭。（这个命令可以在本机运行，也可以在mininet虚拟主机运行。）</p>
<p></p>
<h3 id="配置olsr">配置OLSR</h3>
<p>编辑配置文件：<code>vim /etc/olsrd/olsrd.conf</code></p>
<p>添加所有节点的网卡：</p>
<p></p>
<p>退出、保存</p>
<h3 id="运行拓扑文件">运行拓扑文件</h3>
<p><code>sudo python olsr_test.py olsrd</code></p>
<p></p>
<h3 id="网络测试">网络测试</h3>
<p><code>sta1 ping sta4</code></p>
<p></p>
<p>能ping通，说明OLSR协议运行正常。</p>
<p>查看路由：<code>sta3 route</code></p>
<p></p>
<p>多了三条路由，这是OLSR协议运行的结果。</p>
<h2 id="结束">结束</h2>
<h3 id="恢复系统">恢复系统</h3>
<p>开启NetworkManager：<code>sudo systemctl start NetworkManager</code></p>
<p>退出mininet-wifi：<code>exit</code></p>
<p>清理系统：<code>sudo mn -c</code></p>
<h3 id="参考文献">参考文献</h3>
<p><a href="https://blog.csdn.net/whatday/article/details/106096127" target="_blank" rel="noopener noreffer">centos7 开启 关闭 NetworkManager</a></p>
<p><a href="https://blog.csdn.net/qq_35109869/article/details/79839357" target="_blank" rel="noopener noreffer">Linux虚拟机下OLSR协议的安装</a></p>
<p><a href="https://github.com/intrig-unicamp/mininet-wifi/issues/342" target="_blank" rel="noopener noreffer">Unable to create IPv6 multi hop mesh network in ad hoc mode #342</a>这个issue救了大命了</p>
<p><a href="https://blog.csdn.net/weixin_29279047/article/details/116832580" target="_blank" rel="noopener noreffer">Linux卸载olsrd,olsrd路由协议移植到嵌入式linux中使用</a></p>
<p><a href="www.olsr.org/" rel="">www.olsr.org/</a>官网写的说明太少了，根本看不懂，麻了。</p>
<p><a href="https://github.com/OLSR/olsrd" target="_blank" rel="noopener noreffer">https://github.com/OLSR/olsrd</a></p>
]]></description>
</item>
</channel>
</rss>
